{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3i2Op-6X5n"
      },
      "source": [
        "# **Introduction to Deep Learning: Final Project**\n",
        "\n",
        "**Submitted by:**\n",
        "\n",
        "Roei Matz       205871478\n",
        "\n",
        "Yotam Silverman 313532418"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4Ki8M-pCmgF"
      },
      "source": [
        "# Project Description\n",
        "\n",
        "The data for this project was gathered from the [sign language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist) dataset from the website kaggle.com.\n",
        "\n",
        "\n",
        "The dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2â€¦.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n",
        "\n",
        "Our project's objective is to design and build a neural network that will identify the letters given in each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zdEvcdO6X5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf78ece1-5dc3-41f5-b828-25b5939a3ce1"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# CapsNet related imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# clone package repository\n",
        "!git clone https://github.com/jindongwang/Pytorch-CapsuleNet.git\n",
        "\n",
        "# navigate to directory\n",
        "%cd Pytorch-CapsuleNet\n",
        "\n",
        "# get modifications made on the repo\n",
        "!git pull origin master\n",
        "\n",
        "# import it\n",
        "from capsnet import CapsNet\n",
        "#\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Pytorch-CapsuleNet' already exists and is not an empty directory.\n",
            "/content/Pytorch-CapsuleNet\n",
            "From https://github.com/jindongwang/Pytorch-CapsuleNet\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70FvfUt8E0aX"
      },
      "source": [
        "Mount Google Drive and load the project's data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "PRlPFrSaEoJi",
        "outputId": "c69b67db-93a3-417a-80d1-c731f277faf4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_csv = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_train.csv')\n",
        "test_csv  = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_test.csv')\n",
        "x_train_val = np.genfromtxt(train_csv, delimiter=',')[1:,1:]\n",
        "x_test = np.genfromtxt(test_csv, delimiter=',')[1:,1:]\n",
        "\n",
        "train_csv = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_train.csv')\n",
        "test_csv  = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_test.csv')\n",
        "t_train_val = np.genfromtxt(train_csv, delimiter=',')[1:,0]\n",
        "t_test =  np.genfromtxt(test_csv, delimiter=',')[1:,0]\n",
        "\n",
        "x_train = x_train_val[0:round(0.9*len(x_train_val))]\n",
        "t_train = t_train_val[0:round(0.9*len(t_train_val))]\n",
        "x_val = x_train_val[round(0.9*len(x_train_val)):]\n",
        "t_val = t_train_val[round(0.9*len(t_train_val)):]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-76bbf75c592b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_csv\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_train_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         rows = list(\n\u001b[1;32m   2095\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0;32m-> 2096\u001b[0;31m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[1;32m   2097\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         rows = list(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo6PrBdGsC4M"
      },
      "source": [
        "Here we show few examples of the letters notions in the sign language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzC3fRTiKEZn"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6, 3))\n",
        "for img in x_train: \n",
        "  plt.subplot(1, 5, i + 1)\n",
        "  img = np.reshape(img, (28, 28))\n",
        "  plt.imshow(img, cmap='Greys_r')\n",
        "  plt.axis('off');\n",
        "  i += 1\n",
        "  if i == 5:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8AVb_qUFJIG"
      },
      "source": [
        "Normalizing the data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpn4WesUFUxg"
      },
      "source": [
        "def img_norm(data):\n",
        "  output = []\n",
        "  for img in data: \n",
        "    img = (img - np.mean(img))/np.std(img)\n",
        "    output.append(np.array(img))\n",
        "  return np.array(output)\n",
        "\n",
        "x_train_norm = img_norm(x_train)\n",
        "x_test_norm = img_norm(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rDEbZpSKl6"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_train[:,None], x_train_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_test[:,None], x_test_norm),axis=1),\n",
        "    batch_size=1000, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTzKhbQxR3ik"
      },
      "source": [
        "Defining CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6cZcnLpR1yD"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
        "        self.fc2 = nn.Linear(50, output_size)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = x.view(-1, self.n_feature*4*4)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(epoch, model, lr=0.01, momentum=0.5, perm=torch.arange(0, 784).long()):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    for batch_idx, ar in enumerate(train_loader):\n",
        "        data = ar[:,1:]\n",
        "        label = ar[:,0]\n",
        "        # send to device\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, label.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item())) \n",
        "            \n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "def test(model, perm=torch.arange(0, 784).long()):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for ar in test_loader:\n",
        "        data = ar[:,1:]\n",
        "        label = ar[:,0]\n",
        "        # send to device\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, label.long(), reduction='sum').item() # sum up batch loss                                                               \n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(label.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8PZXeXgSgDh"
      },
      "source": [
        "# Training settings \n",
        "n_features = 10 # number of feature maps\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 26      # there are 26 classes\n",
        "\n",
        "model_cnn = CNN(input_size, n_features, output_size)\n",
        "model_cnn.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "momentum = 0.1\n",
        "\n",
        "for epoch in range(0, 6):\n",
        "    train(epoch, model_cnn.double(), lr)\n",
        "test(model_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use CapsNet:"
      ],
      "metadata": {
        "id": "mWnFPOaVIavV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from capsnet import CapsNet\n",
        "from data_loader import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "BATCH_SIZE = 100\n",
        "N_EPOCHS = 30\n",
        "LEARNING_RATE = 0.01\n",
        "MOMENTUM = 0.9\n",
        "n_features = 10\n",
        "'''\n",
        "Config class to determine the parameters for capsule net\n",
        "'''\n",
        "\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # CNN (cnn)\n",
        "        self.cnn_in_channels = 1\n",
        "        self.cnn_out_channels = 256\n",
        "        self.cnn_kernel_size = 9\n",
        "\n",
        "        # Primary Capsule (pc)\n",
        "        self.pc_num_capsules = 8\n",
        "        self.pc_in_channels = 256\n",
        "        self.pc_out_channels = 32\n",
        "        self.pc_kernel_size = 9\n",
        "        self.pc_num_routes = 32 * 6 * 6\n",
        "\n",
        "        # Digit Capsule (dc)\n",
        "        self.dc_num_capsules = 10\n",
        "        self.dc_num_routes = 32 * 6 * 6\n",
        "        self.dc_in_channels = 8\n",
        "        self.dc_out_channels = 16\n",
        "\n",
        "        # Decoder\n",
        "        self.input_width = 28\n",
        "        self.input_height = 28\n",
        "\n",
        "def new_margin_loss(x, labels, size_average=True):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
        "\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "        print(v_c)\n",
        "        print(batch_size)\n",
        "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "def train_capsnet(model, optimizer, train_loader, epoch):\n",
        "    capsule_net = model\n",
        "    capsule_net.train()\n",
        "    n_batch = len(list(enumerate(train_loader)))\n",
        "    total_loss = 0\n",
        "    for batch_id, ar in enumerate(train_loader):\n",
        "        data = ar[:,1:].type(torch.double)\n",
        "        target = ar[:,0].type(torch.int64)\n",
        "        target = torch.sparse.torch.eye(26).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        perm=torch.arange(0, 784).long()\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
        "        train_loss = loss.item()\n",
        "        total_loss += train_loss\n",
        "        if batch_id % 100 == 0:\n",
        "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}, loss: {:.6f}\".format(\n",
        "                epoch,\n",
        "                N_EPOCHS,\n",
        "                batch_id + 1,\n",
        "                n_batch,\n",
        "                correct / float(BATCH_SIZE),\n",
        "                train_loss / float(BATCH_SIZE)\n",
        "                ))\n",
        "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,N_EPOCHS,total_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test_capsnet(capsule_net, test_loader, epoch):\n",
        "    capsule_net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for batch_id, (data, target) in enumerate(test_loader):\n",
        "\n",
        "        target = torch.sparse.torch.eye(26).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
        "                       np.argmax(target.data.cpu().numpy(), 1))\n",
        "\n",
        "    tqdm.write(\n",
        "        \"Epoch: [{}/{}], test accuracy: {:.6f}, loss: {:.6f}\".format(epoch, N_EPOCHS, correct / len(test_loader.dataset),\n",
        "                                                                  test_loss / len(test_loader)))\n",
        "    \n",
        "\n",
        "torch.manual_seed(1)\n",
        "config = Config()\n",
        "\n",
        "capsule_net = CapsNet(config)\n",
        "capsule_net = torch.nn.DataParallel(capsule_net)\n",
        "if USE_CUDA:\n",
        "    capsule_net = capsule_net.cuda()\n",
        "capsule_net = capsule_net.module.double()\n",
        "\n",
        "optimizer = torch.optim.Adam(capsule_net.parameters())\n",
        "capsule_net.margin_loss = new_margin_loss\n",
        "for e in range(1, N_EPOCHS + 1):\n",
        "    train_capsnet(capsule_net, optimizer, train_loader, e)\n",
        "    test_capsnet(capsule_net, test_loader, e)\n",
        "    # train(e, capsule_net)\n",
        "    # test(capsule_net)"
      ],
      "metadata": {
        "id": "SL73PRG8IZlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}