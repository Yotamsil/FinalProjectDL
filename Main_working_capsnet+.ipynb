{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3i2Op-6X5n"
      },
      "source": [
        "# **Introduction to Deep Learning: Final Project**\n",
        "\n",
        "**Submitted by:**\n",
        "\n",
        "Roei Matz       205871478\n",
        "\n",
        "Yotam Silverman 313532418"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4Ki8M-pCmgF"
      },
      "source": [
        "# Project Description\n",
        "\n",
        "The data for this project was gathered from the [sign language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist) dataset from the website kaggle.com.\n",
        "\n",
        "\n",
        "The dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2â€¦.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n",
        "\n",
        "Our project's objective is to design and build a neural network that will identify the letters given in each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zdEvcdO6X5s"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# CapsNet related imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "# # clone package repository\n",
        "# !git clone https://github.com/jindongwang/Pytorch-CapsuleNet.git\n",
        "\n",
        "# # navigate to directory\n",
        "# %cd Pytorch-CapsuleNet\n",
        "\n",
        "# # get modifications made on the repo\n",
        "# !git pull origin master\n",
        "\n",
        "# # import it\n",
        "# from capsnet import CapsNet\n",
        "\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70FvfUt8E0aX"
      },
      "source": [
        "Mount Google Drive and load the project's data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRlPFrSaEoJi",
        "outputId": "3d5bd3e5-bf46-4e3b-99c3-1098ae01385a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_csv = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_train.csv')\n",
        "test_csv  = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_test.csv')\n",
        "x_train_val = np.genfromtxt(train_csv, delimiter=',')[1:,1:]\n",
        "x_test = np.genfromtxt(test_csv, delimiter=',')[1:,1:]\n",
        "\n",
        "train_csv = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_train.csv')\n",
        "test_csv  = open('/content/gdrive/My Drive/Intro_to_Deep_Learning/sign_mnist_test.csv')\n",
        "t_train_val = np.genfromtxt(train_csv, delimiter=',')[1:,0]\n",
        "t_test =  np.genfromtxt(test_csv, delimiter=',')[1:,0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the train set to train and validation:"
      ],
      "metadata": {
        "id": "SwPEZ6Xpc77u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train_val[0:round(0.8*len(x_train_val))]\n",
        "x_val = x_train_val[round(0.8*len(x_train_val)):]\n",
        "\n",
        "t_train = t_train_val[0:round(0.8*len(t_train_val))]\n",
        "t_val = t_train_val[round(0.8*len(t_train_val)):]"
      ],
      "metadata": {
        "id": "7PBs_xGAdAt1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a dictionary for the alphabet:"
      ],
      "metadata": {
        "id": "KzfWCyP27hnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet_dict = dict(zip(range(0,26),string.ascii_uppercase))\n",
        "\n",
        "print(alphabet_dict)"
      ],
      "metadata": {
        "id": "4g1lTM9d7fb1",
        "outputId": "611162ba-3c63-4199-e8ad-e864bb9089fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo6PrBdGsC4M"
      },
      "source": [
        "Here, we show few examples of the letters notions in the sign language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PzC3fRTiKEZn",
        "outputId": "ebda6c03-44e1-4c3b-e670-0281b9b78e92"
      },
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "for i in range(0,5): \n",
        "  plt.subplot(1, 5, i + 1)\n",
        "  img = x_train[i]\n",
        "  img = np.reshape(img, (28, 28))\n",
        "  plt.imshow(img, cmap='Greys_r')\n",
        "  plt.title(alphabet_dict[int(t_train[i])])\n",
        "  plt.axis('off');"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8AVb_qUFJIG"
      },
      "source": [
        "Normalizing the data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpn4WesUFUxg"
      },
      "source": [
        "def img_norm(data):\n",
        "  output = []\n",
        "  for img in data: \n",
        "    img = (img - np.mean(img))/np.std(img)  #zero mean and a unit standard deviation\n",
        "    output.append(np.array(img))\n",
        "  return np.array(output)\n",
        "\n",
        "# def img_norm(data): # 63% accuracy\n",
        "#   output = []\n",
        "#   for img in data: \n",
        "#     img = img/255                        #pixels' values between 0 to 1\n",
        "#     output.append(np.array(img))\n",
        "#   return np.array(output)\n",
        "\n",
        "# def img_norm(data): # 78% accuracy\n",
        "#   output = []\n",
        "#   for img in data: \n",
        "#     img = img/255 - 0.5                 #pixels' values between -0.5 to 0.5\n",
        "#     output.append(np.array(img))\n",
        "#   return np.array(output)\n",
        "\n",
        "x_train_norm = img_norm(x_train)\n",
        "x_val_norm = img_norm(x_val)\n",
        "x_test_norm = img_norm(x_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_train[:,None], x_train_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_val[:,None], x_val_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    np.concatenate((t_test[:,None], x_test_norm),axis=1),\n",
        "    batch_size=64, shuffle=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking the network with several normalztions techniques, such as: dividing each image by 255 so we will have values between 0 and 1, and also subtracting 0.5 so that the elements of will be between -0.5 and 0.5, we chose to normalize by subtracting the mean of each image and dividing the standard deviation. This normaliztion provided the best accuracy with our models."
      ],
      "metadata": {
        "id": "9MPFKCtDmUtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to examine the model performance, we used a confusion matrix. \n",
        "The confusion matrix will show us the numbers of correct predictions vs number of wrong predictions for each letter."
      ],
      "metadata": {
        "id": "fjHUGWOznKF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_confusion_matrix(conf_mat):\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=[alphabet_dict[i] for i in list(range(0,9))+list(range(10,25))])\n",
        "    fig, ax = plt.subplots(figsize=(14, 12))\n",
        "    ax.set_xlabel('Preicted Label', fontsize=16)\n",
        "    ax.set_ylabel('True Label', fontsize=16) \n",
        "    disp.plot(ax=ax)"
      ],
      "metadata": {
        "id": "qAIL7-qCnIwU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTzKhbQxR3ik"
      },
      "source": [
        "Defining CNN model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6cZcnLpR1yD"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size, num_of_layers):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.num_of_layers = num_of_layers\n",
        "        self.length_calc = int(np.floor(np.sqrt(input_size)//(2**num_of_layers)))  \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5, padding='same')\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5, padding='same')\n",
        "        self.conv3 = nn.Conv2d(n_feature, n_feature, kernel_size=5, padding='same')        \n",
        "        self.fc1 = nn.Linear(n_feature*self.length_calc*self.length_calc, 50)\n",
        "        self.fc2 = nn.Linear(50, output_size)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv1(x)                   \n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        if self.num_of_layers > 1:\n",
        "          x = self.conv2(x)\n",
        "          x = F.relu(x)\n",
        "          x = F.max_pool2d(x, kernel_size=2)\n",
        "          if self.num_of_layers > 2:\n",
        "            x = self.conv3(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.max_pool2d(x, kernel_size=2)\n",
        "            \n",
        "        x = x.view(-1, self.n_feature*self.length_calc*self.length_calc)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining accuracy measure function and a training function:"
      ],
      "metadata": {
        "id": "llvJcX4PqCPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, loader=train_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    for ar in loader:\n",
        "        data = ar[:,1:]\n",
        "        label = ar[:,0]\n",
        "        # send to device\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        \n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        pred = model(data)\n",
        "        loss += F.nll_loss(pred, label.long(), reduction='sum').item() # sum up batch loss                                                               \n",
        "        pred = pred.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(label.data.view_as(pred)).cpu().sum().item()\n",
        " \n",
        "        for y in pred.squeeze(1):\n",
        "          pred_list.append(y.cpu())\n",
        "\n",
        "        for y in label:  \n",
        "          true_list.append(y.cpu())\n",
        "          \n",
        "    conf_mat = confusion_matrix(true_list, pred_list, labels=list(range(0,9))+list(range(10,25)))    \n",
        "    loss /= len(loader.dataset)\n",
        "    accuracy = 100. * correct / len(loader.dataset)\n",
        "    \n",
        "    return loss, accuracy, conf_mat\n",
        "\n",
        "def train(model, lr=0.01, momentum=0.5, max_iters=1000,num_epochs=6,show_prints=True):\n",
        "    model.train()\n",
        "    train_accs, valid_accs = [], []\n",
        "    epochs = []\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    n = 0 # the number of iterations\n",
        "    iters, losses = [], []\n",
        "    iters_sub = []\n",
        "\n",
        "    for epoch in range(0, num_epochs):\n",
        "\n",
        "        for batch_idx, ar in enumerate(train_loader):           \n",
        "            data = ar[:,1:]\n",
        "            label = ar[:,0]\n",
        "            # send to device\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            data = data.view(-1, 28*28)\n",
        "            data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data)\n",
        "            loss = F.nll_loss(pred, label.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            iters.append(n)\n",
        "            losses.append(loss)\n",
        "\n",
        "            if batch_idx % 64 == 0: \n",
        "                \n",
        "                iters_sub.append(n)\n",
        "                train_loss, train_acc, _ = get_accuracy(model, loader=train_loader)\n",
        "                train_accs.append(train_acc)\n",
        "\n",
        "                valid_loss, valid_acc, _ = get_accuracy(model, loader=val_loader)\n",
        "                valid_accs.append(valid_acc)\n",
        "                if show_prints:\n",
        "                  print(\"Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]\" % (n, valid_acc, train_acc, train_loss))\n",
        "\n",
        "            # increment the iteration number\n",
        "            n += 1\n",
        "            if n > max_iters:\n",
        "                return iters, losses, iters_sub, train_accs, valid_accs\n",
        "    return iters, losses, iters_sub, train_accs, valid_accs"
      ],
      "metadata": {
        "id": "RdU0GU5SpvEm"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings \n",
        "n_features = 10       # number of feature maps\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 26      # there are 26 classes"
      ],
      "metadata": {
        "id": "iSUF9Lw2DUBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried several CNNs using different number of layers.\n",
        "\n",
        "Here, we defined 3 CNNs with one layer, two layers and three layers:"
      ],
      "metadata": {
        "id": "EMkASkc6rEzA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8PZXeXgSgDh",
        "outputId": "d7148d12-f552-4043-9c7f-26758e0e1b0b"
      },
      "source": [
        "model_cnn1 = CNN(input_size, n_features, output_size,1)\n",
        "model_cnn1.to(device)\n",
        "model_cnn2 = CNN(input_size, n_features, output_size,num_of_layers=2)\n",
        "model_cnn2.to(device)\n",
        "model_cnn3 = CNN(input_size, n_features, output_size,3)\n",
        "model_cnn3.to(device)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "  (conv3): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "  (fc1): Linear(in_features=90, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "momentum = 0.1\n",
        "\n",
        "iters, losses, iters_sub, train_accs, valid_accs = train(model_cnn1.double(), lr=lr, momentum=momentum, max_iters=640,num_epochs=6,show_prints=False)\n",
        "iters, losses, iters_sub, train_accs, valid_accs = train(model_cnn2.double(), lr=lr, momentum=momentum, max_iters=640,num_epochs=6,show_prints=False)\n",
        "iters, losses, iters_sub, train_accs, valid_accs = train(model_cnn3.double(), lr=lr, momentum=momentum, max_iters=640,num_epochs=6,show_prints=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdTodunAy1de",
        "outputId": "16aafab6-7170-4254-e139-c80ca90a5e06"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  48,\n",
              "  49,\n",
              "  50,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  55,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  83,\n",
              "  84,\n",
              "  85,\n",
              "  86,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  90,\n",
              "  91,\n",
              "  92,\n",
              "  93,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  105,\n",
              "  106,\n",
              "  107,\n",
              "  108,\n",
              "  109,\n",
              "  110,\n",
              "  111,\n",
              "  112,\n",
              "  113,\n",
              "  114,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  118,\n",
              "  119,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  123,\n",
              "  124,\n",
              "  125,\n",
              "  126,\n",
              "  127,\n",
              "  128,\n",
              "  129,\n",
              "  130,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  145,\n",
              "  146,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  157,\n",
              "  158,\n",
              "  159,\n",
              "  160,\n",
              "  161,\n",
              "  162,\n",
              "  163,\n",
              "  164,\n",
              "  165,\n",
              "  166,\n",
              "  167,\n",
              "  168,\n",
              "  169,\n",
              "  170,\n",
              "  171,\n",
              "  172,\n",
              "  173,\n",
              "  174,\n",
              "  175,\n",
              "  176,\n",
              "  177,\n",
              "  178,\n",
              "  179,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  183,\n",
              "  184,\n",
              "  185,\n",
              "  186,\n",
              "  187,\n",
              "  188,\n",
              "  189,\n",
              "  190,\n",
              "  191,\n",
              "  192,\n",
              "  193,\n",
              "  194,\n",
              "  195,\n",
              "  196,\n",
              "  197,\n",
              "  198,\n",
              "  199,\n",
              "  200,\n",
              "  201,\n",
              "  202,\n",
              "  203,\n",
              "  204,\n",
              "  205,\n",
              "  206,\n",
              "  207,\n",
              "  208,\n",
              "  209,\n",
              "  210,\n",
              "  211,\n",
              "  212,\n",
              "  213,\n",
              "  214,\n",
              "  215,\n",
              "  216,\n",
              "  217,\n",
              "  218,\n",
              "  219,\n",
              "  220,\n",
              "  221,\n",
              "  222,\n",
              "  223,\n",
              "  224,\n",
              "  225,\n",
              "  226,\n",
              "  227,\n",
              "  228,\n",
              "  229,\n",
              "  230,\n",
              "  231,\n",
              "  232,\n",
              "  233,\n",
              "  234,\n",
              "  235,\n",
              "  236,\n",
              "  237,\n",
              "  238,\n",
              "  239,\n",
              "  240,\n",
              "  241,\n",
              "  242,\n",
              "  243,\n",
              "  244,\n",
              "  245,\n",
              "  246,\n",
              "  247,\n",
              "  248,\n",
              "  249,\n",
              "  250,\n",
              "  251,\n",
              "  252,\n",
              "  253,\n",
              "  254,\n",
              "  255,\n",
              "  256,\n",
              "  257,\n",
              "  258,\n",
              "  259,\n",
              "  260,\n",
              "  261,\n",
              "  262,\n",
              "  263,\n",
              "  264,\n",
              "  265,\n",
              "  266,\n",
              "  267,\n",
              "  268,\n",
              "  269,\n",
              "  270,\n",
              "  271,\n",
              "  272,\n",
              "  273,\n",
              "  274,\n",
              "  275,\n",
              "  276,\n",
              "  277,\n",
              "  278,\n",
              "  279,\n",
              "  280,\n",
              "  281,\n",
              "  282,\n",
              "  283,\n",
              "  284,\n",
              "  285,\n",
              "  286,\n",
              "  287,\n",
              "  288,\n",
              "  289,\n",
              "  290,\n",
              "  291,\n",
              "  292,\n",
              "  293,\n",
              "  294,\n",
              "  295,\n",
              "  296,\n",
              "  297,\n",
              "  298,\n",
              "  299,\n",
              "  300,\n",
              "  301,\n",
              "  302,\n",
              "  303,\n",
              "  304,\n",
              "  305,\n",
              "  306,\n",
              "  307,\n",
              "  308,\n",
              "  309,\n",
              "  310,\n",
              "  311,\n",
              "  312,\n",
              "  313,\n",
              "  314,\n",
              "  315,\n",
              "  316,\n",
              "  317,\n",
              "  318,\n",
              "  319,\n",
              "  320,\n",
              "  321,\n",
              "  322,\n",
              "  323,\n",
              "  324,\n",
              "  325,\n",
              "  326,\n",
              "  327,\n",
              "  328,\n",
              "  329,\n",
              "  330,\n",
              "  331,\n",
              "  332,\n",
              "  333,\n",
              "  334,\n",
              "  335,\n",
              "  336,\n",
              "  337,\n",
              "  338,\n",
              "  339,\n",
              "  340,\n",
              "  341,\n",
              "  342,\n",
              "  343,\n",
              "  344,\n",
              "  345,\n",
              "  346,\n",
              "  347,\n",
              "  348,\n",
              "  349,\n",
              "  350,\n",
              "  351,\n",
              "  352,\n",
              "  353,\n",
              "  354,\n",
              "  355,\n",
              "  356,\n",
              "  357,\n",
              "  358,\n",
              "  359,\n",
              "  360,\n",
              "  361,\n",
              "  362,\n",
              "  363,\n",
              "  364,\n",
              "  365,\n",
              "  366,\n",
              "  367,\n",
              "  368,\n",
              "  369,\n",
              "  370,\n",
              "  371,\n",
              "  372,\n",
              "  373,\n",
              "  374,\n",
              "  375,\n",
              "  376,\n",
              "  377,\n",
              "  378,\n",
              "  379,\n",
              "  380,\n",
              "  381,\n",
              "  382,\n",
              "  383,\n",
              "  384,\n",
              "  385,\n",
              "  386,\n",
              "  387,\n",
              "  388,\n",
              "  389,\n",
              "  390,\n",
              "  391,\n",
              "  392,\n",
              "  393,\n",
              "  394,\n",
              "  395,\n",
              "  396,\n",
              "  397,\n",
              "  398,\n",
              "  399,\n",
              "  400,\n",
              "  401,\n",
              "  402,\n",
              "  403,\n",
              "  404,\n",
              "  405,\n",
              "  406,\n",
              "  407,\n",
              "  408,\n",
              "  409,\n",
              "  410,\n",
              "  411,\n",
              "  412,\n",
              "  413,\n",
              "  414,\n",
              "  415,\n",
              "  416,\n",
              "  417,\n",
              "  418,\n",
              "  419,\n",
              "  420,\n",
              "  421,\n",
              "  422,\n",
              "  423,\n",
              "  424,\n",
              "  425,\n",
              "  426,\n",
              "  427,\n",
              "  428,\n",
              "  429,\n",
              "  430,\n",
              "  431,\n",
              "  432,\n",
              "  433,\n",
              "  434,\n",
              "  435,\n",
              "  436,\n",
              "  437,\n",
              "  438,\n",
              "  439,\n",
              "  440,\n",
              "  441,\n",
              "  442,\n",
              "  443,\n",
              "  444,\n",
              "  445,\n",
              "  446,\n",
              "  447,\n",
              "  448,\n",
              "  449,\n",
              "  450,\n",
              "  451,\n",
              "  452,\n",
              "  453,\n",
              "  454,\n",
              "  455,\n",
              "  456,\n",
              "  457,\n",
              "  458,\n",
              "  459,\n",
              "  460,\n",
              "  461,\n",
              "  462,\n",
              "  463,\n",
              "  464,\n",
              "  465,\n",
              "  466,\n",
              "  467,\n",
              "  468,\n",
              "  469,\n",
              "  470,\n",
              "  471,\n",
              "  472,\n",
              "  473,\n",
              "  474,\n",
              "  475,\n",
              "  476,\n",
              "  477,\n",
              "  478,\n",
              "  479,\n",
              "  480,\n",
              "  481,\n",
              "  482,\n",
              "  483,\n",
              "  484,\n",
              "  485,\n",
              "  486,\n",
              "  487,\n",
              "  488,\n",
              "  489,\n",
              "  490,\n",
              "  491,\n",
              "  492,\n",
              "  493,\n",
              "  494,\n",
              "  495,\n",
              "  496,\n",
              "  497,\n",
              "  498,\n",
              "  499,\n",
              "  500,\n",
              "  501,\n",
              "  502,\n",
              "  503,\n",
              "  504,\n",
              "  505,\n",
              "  506,\n",
              "  507,\n",
              "  508,\n",
              "  509,\n",
              "  510,\n",
              "  511,\n",
              "  512,\n",
              "  513,\n",
              "  514,\n",
              "  515,\n",
              "  516,\n",
              "  517,\n",
              "  518,\n",
              "  519,\n",
              "  520,\n",
              "  521,\n",
              "  522,\n",
              "  523,\n",
              "  524,\n",
              "  525,\n",
              "  526,\n",
              "  527,\n",
              "  528,\n",
              "  529,\n",
              "  530,\n",
              "  531,\n",
              "  532,\n",
              "  533,\n",
              "  534,\n",
              "  535,\n",
              "  536,\n",
              "  537,\n",
              "  538,\n",
              "  539,\n",
              "  540,\n",
              "  541,\n",
              "  542,\n",
              "  543,\n",
              "  544,\n",
              "  545,\n",
              "  546,\n",
              "  547,\n",
              "  548,\n",
              "  549,\n",
              "  550,\n",
              "  551,\n",
              "  552,\n",
              "  553,\n",
              "  554,\n",
              "  555,\n",
              "  556,\n",
              "  557,\n",
              "  558,\n",
              "  559,\n",
              "  560,\n",
              "  561,\n",
              "  562,\n",
              "  563,\n",
              "  564,\n",
              "  565,\n",
              "  566,\n",
              "  567,\n",
              "  568,\n",
              "  569,\n",
              "  570,\n",
              "  571,\n",
              "  572,\n",
              "  573,\n",
              "  574,\n",
              "  575,\n",
              "  576,\n",
              "  577,\n",
              "  578,\n",
              "  579,\n",
              "  580,\n",
              "  581,\n",
              "  582,\n",
              "  583,\n",
              "  584,\n",
              "  585,\n",
              "  586,\n",
              "  587,\n",
              "  588,\n",
              "  589,\n",
              "  590,\n",
              "  591,\n",
              "  592,\n",
              "  593,\n",
              "  594,\n",
              "  595,\n",
              "  596,\n",
              "  597,\n",
              "  598,\n",
              "  599,\n",
              "  600,\n",
              "  601,\n",
              "  602,\n",
              "  603,\n",
              "  604,\n",
              "  605,\n",
              "  606,\n",
              "  607,\n",
              "  608,\n",
              "  609,\n",
              "  610,\n",
              "  611,\n",
              "  612,\n",
              "  613,\n",
              "  614,\n",
              "  615,\n",
              "  616,\n",
              "  617,\n",
              "  618,\n",
              "  619,\n",
              "  620,\n",
              "  621,\n",
              "  622,\n",
              "  623,\n",
              "  624,\n",
              "  625,\n",
              "  626,\n",
              "  627,\n",
              "  628,\n",
              "  629,\n",
              "  630,\n",
              "  631,\n",
              "  632,\n",
              "  633,\n",
              "  634,\n",
              "  635,\n",
              "  636,\n",
              "  637,\n",
              "  638,\n",
              "  639,\n",
              "  640],\n",
              " [tensor(0.1120, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0878, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4741, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2877, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0668, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2645, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1659, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2038, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3552, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1932, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2110, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1516, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1554, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1155, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0684, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1153, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0893, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1849, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1191, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0296, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0872, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0994, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1513, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1116, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0812, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1389, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1180, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0447, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1017, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0497, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0774, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0873, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0654, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0482, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1644, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0933, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0511, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1298, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1382, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0886, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0740, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0958, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0866, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1568, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0808, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0892, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1659, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0756, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1107, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1007, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0376, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1597, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1707, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0449, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0869, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0837, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0913, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0510, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0724, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0762, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0642, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0491, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1802, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1313, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0914, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1109, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1163, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0950, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1584, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1572, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1942, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1851, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1190, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0508, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0595, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0569, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0807, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1250, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1359, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0762, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0579, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0629, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1045, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1028, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0459, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0362, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0905, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0674, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0483, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0748, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1401, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0626, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0371, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1112, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0247, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0661, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0920, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1060, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0695, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0696, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1172, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0688, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0564, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0204, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0414, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0581, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0974, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0386, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1183, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0465, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0804, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0653, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0460, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0504, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1180, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0801, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1040, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0598, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0960, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0891, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1203, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0644, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1279, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1137, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1818, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0451, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0442, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0613, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0391, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0427, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0419, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0404, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0758, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0752, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0462, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0216, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0759, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1120, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0715, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0471, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0634, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0384, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0684, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1288, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0713, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0698, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0591, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0263, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0799, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2883, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0438, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0466, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1181, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1282, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0197, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0379, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0464, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0526, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0214, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0406, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0350, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0556, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1600, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0632, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0419, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0317, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0865, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0654, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0823, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0518, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0549, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0339, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0309, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0434, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0672, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0270, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0370, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0214, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0275, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0197, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0502, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0338, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0256, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0336, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0221, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0286, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0273, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0252, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0340, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0313, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0714, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0126, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0170, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0219, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0401, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0188, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0260, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0205, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0128, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0153, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0084, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0344, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0721, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0349, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0124, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0246, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1366, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0348, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0258, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0205, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0360, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0588, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0591, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0291, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0324, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0310, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0436, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1132, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0727, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0508, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0679, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0345, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0186, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0160, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0565, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0356, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0826, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0469, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1039, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0189, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0689, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1113, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0201, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0214, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0561, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0526, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0460, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0505, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0328, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0801, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0448, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0311, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0218, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0247, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0206, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0334, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0351, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0285, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0470, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0149, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0165, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0225, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0458, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0441, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0260, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0306, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0359, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0243, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0294, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0458, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0349, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0147, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0181, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0268, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1794, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0616, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0368, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0124, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0145, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0247, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0587, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0372, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0541, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0377, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0161, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0920, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0499, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0448, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1123, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0253, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0351, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0181, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0200, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0267, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1155, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0155, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0222, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0293, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0141, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0449, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0562, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0071, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0181, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0325, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0333, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0482, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0282, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0196, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0425, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0177, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0423, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0502, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0178, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0259, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0081, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0381, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0416, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0629, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0405, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0569, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0398, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0730, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0667, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0177, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0289, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0210, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0254, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0346, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0442, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0705, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0365, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0348, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0142, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0638, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0213, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0071, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0299, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0684, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0423, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0845, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0348, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0660, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0199, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0141, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0086, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0634, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0800, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0454, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0583, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1126, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0297, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0216, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0060, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0140, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0287, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1298, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0652, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0332, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0712, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0175, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0223, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1201, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0392, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0209, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0427, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0314, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0154, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0535, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1049, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0151, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0212, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0539, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0346, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0227, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0214, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0119, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0140, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0326, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0886, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0255, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0320, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0501, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0256, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0385, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0491, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0417, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0289, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0044, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0133, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0306, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0310, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0228, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0187, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0284, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0272, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0250, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0091, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0111, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0680, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0141, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0409, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0328, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0314, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0166, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0157, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0182, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0276, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0287, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0089, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0305, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0136, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0054, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0219, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0373, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0197, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0230, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0069, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0172, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0036, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0055, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0226, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0089, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0068, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0138, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0085, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0117, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0042, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0122, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0192, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0169, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0162, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0040, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0118, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0092, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0244, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0172, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0097, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0075, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0192, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0041, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0136, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0392, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0089, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0055, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0046, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0063, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0082, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0042, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0176, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0282, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0102, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0023, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0096, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0072, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0226, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0107, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0078, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0512, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0053, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0071, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0080, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0092, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0094, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0264, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0040, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0068, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0064, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0077, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0078, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0075, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0079, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0064, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0042, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0255, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0152, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0123, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0082, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0289, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0140, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0090, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0140, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0076, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0049, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0262, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0256, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0092, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0058, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0201, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0466, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0142, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0127, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0089, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0138, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0301, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0109, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0259, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0138, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0079, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0062, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0353, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0045, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0083, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0170, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0263, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0699, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0045, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0041, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0341, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2324, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0074, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0293, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0089, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0246, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0274, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0333, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0382, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0723, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0406, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0095, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0371, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0729, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0510, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0637, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0318, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0353, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0112, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0184, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0537, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0360, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0609, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0145, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0205, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0733, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0199, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0450, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0103, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0397, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0852, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0305, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0401, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0643, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0241, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1420, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0534, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0486, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0301, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0448, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0558, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0336, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0155, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1237, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0682, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0501, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0244, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0775, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0721, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0376, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1202, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0079, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1179, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0769, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0889, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1059, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0349, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0956, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0837, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0595, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1257, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0689, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0549, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0849, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2978, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1892, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0471, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0692, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1536, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.4762, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1128, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0722, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3805, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2700, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1169, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0726, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0983, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.3617, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0563, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1136, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1127, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0548, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0578, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2485, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0241, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0624, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1023, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0942, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1042, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1653, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0919, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1071, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2729, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1623, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0512, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0189, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0440, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0080, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1130, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0843, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0471, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0313, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1138, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0092, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0220, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0885, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0162, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0093, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0848, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0780, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0144, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0417, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0522, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0160, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0844, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0561, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1513, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0173, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0060, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0277, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0344, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0361, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0427, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.1038, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2006, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0173, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0162, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0073, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0937, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0815, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.2072, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0572, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0072, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0211, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0262, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0790, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0717, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0409, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>),\n",
              "  tensor(0.0099, device='cuda:0', dtype=torch.float64,\n",
              "         grad_fn=<NllLossBackward0>)],\n",
              " [0, 64, 128, 192, 256, 320, 344, 408, 472, 536, 600],\n",
              " [96.21653615006375,\n",
              "  97.64614824257876,\n",
              "  98.9664906210162,\n",
              "  99.70861409579311,\n",
              "  98.72973957384812,\n",
              "  99.19413585867784,\n",
              "  98.42924786013477,\n",
              "  99.68584957202695,\n",
              "  99.89528319067566,\n",
              "  96.84938991076307,\n",
              "  97.8191586232016],\n",
              " [96.59442724458205,\n",
              "  97.70533600437079,\n",
              "  98.54307047896557,\n",
              "  99.70861409579311,\n",
              "  98.48843562192678,\n",
              "  99.14405390639227,\n",
              "  98.433800764888,\n",
              "  99.58113276270261,\n",
              "  99.83609542888362,\n",
              "  96.94044800582772,\n",
              "  98.16062647969405])"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we recieved the best results for the one layer and two layers networks (both of them with accuracy of 86% vs the accuracy of three layers with accuracy of 79%)."
      ],
      "metadata": {
        "id": "y3N5RDOdEJ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc_1, test_conf_mat = get_accuracy(model_cnn1,loader=test_loader)\n",
        "print(\"Test set for 1 layer: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc_1)) \n",
        "test_loss, test_acc_2, test_conf_mat = get_accuracy(model_cnn2,loader=test_loader)\n",
        "print(\"Test set for 2 layers: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc_2)) \n",
        "test_loss, test_acc_3, test_conf_mat = get_accuracy(model_cnn3,loader=test_loader)\n",
        "print(\"Test set for 3 layers: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc_3)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zld7D0DurOHn",
        "outputId": "c03de81a-ed39-4759-faf2-67a1070d6336"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set1: Average loss: 0.523577, Accuracy: 86%\n",
            "Test set2: Average loss: 0.548632, Accuracy: 86%\n",
            "Test set3: Average loss: 0.697824, Accuracy: 79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will check the performance changing the learning rate."
      ],
      "metadata": {
        "id": "sdYFljkYEoQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [x / 10000 for x in range(1, 100, 10)]\n",
        "lr_accs_1 = []\n",
        "lr_accs_2 = []\n",
        "\n",
        "for lr in lrs:\n",
        "    # reseting the model\n",
        "    model_cnn1 = CNN(input_size, n_features, output_size,num_of_layers=1)\n",
        "    model_cnn1.to(device)\n",
        "    model_cnn2 = CNN(input_size, n_features, output_size,num_of_layers=2)\n",
        "    model_cnn2.to(device)\n",
        "    print(f\"---learning rate: {lr}---\")\n",
        "    train(model_cnn1.double(), lr=lr, momentum=momentum, max_iters=640,num_epochs=6,show_prints=False)\n",
        "    train(model_cnn2.double(), lr=lr, momentum=momentum, max_iters=640,num_epochs=6,show_prints=False)\n",
        "    test_loss, test_acc_1, test_conf_mat = get_accuracy(model_cnn1,loader=test_loader)\n",
        "    print(\"Test set for 1 layer: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc_1)) \n",
        "    lr_accs_1.append(test_acc_1)\n",
        "    test_loss, test_acc_2, test_conf_mat = get_accuracy(model_cnn2,loader=test_loader)\n",
        "    print(\"Test set for 2 layers: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc_2)) \n",
        "    lr_accs_2.append(test_acc_2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udT_WcMhFMx0",
        "outputId": "50a2b5c2-cb62-4ec2-e3e0-9965f1f816d0"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---learning rate: 0.0001---\n",
            "Test set for 1 layer: Average loss: 0.939509, Accuracy: 73%\n",
            "Test set for 2 layers: Average loss: 1.220276, Accuracy: 61%\n",
            "---learning rate: 0.0011---\n",
            "Test set for 1 layer: Average loss: 0.524732, Accuracy: 87%\n",
            "Test set for 2 layers: Average loss: 0.494849, Accuracy: 87%\n",
            "---learning rate: 0.0021---\n",
            "Test set for 1 layer: Average loss: 0.524122, Accuracy: 87%\n",
            "Test set for 2 layers: Average loss: 0.411878, Accuracy: 91%\n",
            "---learning rate: 0.0031---\n",
            "Test set for 1 layer: Average loss: 0.619163, Accuracy: 87%\n",
            "Test set for 2 layers: Average loss: 0.322142, Accuracy: 92%\n",
            "---learning rate: 0.0041---\n",
            "Test set for 1 layer: Average loss: 0.502694, Accuracy: 88%\n",
            "Test set for 2 layers: Average loss: 0.447770, Accuracy: 92%\n",
            "---learning rate: 0.0051---\n",
            "Test set for 1 layer: Average loss: 0.560144, Accuracy: 86%\n",
            "Test set for 2 layers: Average loss: 0.398973, Accuracy: 91%\n",
            "---learning rate: 0.0061---\n",
            "Test set for 1 layer: Average loss: 0.564160, Accuracy: 89%\n",
            "Test set for 2 layers: Average loss: 0.583703, Accuracy: 89%\n",
            "---learning rate: 0.0071---\n",
            "Test set for 1 layer: Average loss: 0.712245, Accuracy: 88%\n",
            "Test set for 2 layers: Average loss: 0.325981, Accuracy: 92%\n",
            "---learning rate: 0.0081---\n",
            "Test set for 1 layer: Average loss: 0.620663, Accuracy: 87%\n",
            "Test set for 2 layers: Average loss: 0.532775, Accuracy: 89%\n",
            "---learning rate: 0.0091---\n",
            "Test set for 1 layer: Average loss: 0.948738, Accuracy: 86%\n",
            "Test set for 2 layers: Average loss: 0.750439, Accuracy: 88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot the learning curves: the training loss curve and the training and validation accuracies curves."
      ],
      "metadata": {
        "id": "vWjaLQl_2Ly0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(iters, losses, iters_sub, train_accs, val_accs):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per Iteration\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy per Iteration\")\n",
        "    plt.plot(iters_sub, train_accs, label=\"Train\")\n",
        "    plt.plot(iters_sub, val_accs, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SQ81JL_3YJ0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(iters, losses, iters_sub, train_accs, valid_accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "7aGsERUtaSjZ",
        "outputId": "3115d45a-cf0a-4a22-b276-0d5c2d7f23f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wVZfb48c9JL0BCQkAgQJAWQOmISBHEiigWFLGBXdfvquu6q+66rq6662+X11rWyuqKHRUUu0gRRFQgFJEmTUogQAIBkkDKTc7vj5nES0wghNxMknver9d95U4/z72TOXeeZ+YZUVWMMcYYgBCvAzDGGFN3WFIwxhhTxpKCMcaYMpYUjDHGlLGkYIwxpowlBWOMMWUsKZjDiMgQEfnJ6ziMqUkikisiJ3odR31gSaEOEZHNInKmlzGo6nxV7RKo9YvIOSLytYjkiEimiMwTkQsDtb3jJSLDRERF5F6vY6mv/PdrEZkgIt8EeHtzReRG/3Gq2khVNwVyuw2FJYUgIyKhHm57DPAe8BqQDLQAHgQuqMa6RERqY/8dD+wFrq2FbZWpxfLVmNqIWUTCArl+A6iqverIC9gMnFnB+BDgPmAjsAd4F0jwm/4esBPYD3wNdPebNhl4HvgMyAPOdLdzD7DCXeYdIMqdfxiQXi6mCud1p/8RyAB2ADcCCnSsoAwCbAX+cITyPwS84Tec4q4vzB2eCzwGLAAOAfcCaeXW8TvgI/d9JDDR3e4u4AUg+hi+j1ggB7gCKAT6lZt+E7DGnWc10Mcd3wZ4H8h0v69nqlm+jsB1ftvYBNxSLobRwHLggLt/nAtcBiwpN9/dwIeVlHMu8A9gkbueD8vtX6cC3wL7gB+AYeWWPSzmyvZroCuQDxQDucC+o31PuPuj+13vBF4HmgKfuJ9vtvs+2Z3/MXf9+e42Sj/7sv0SiMP5YZIJbAEeAELcaROAb9x4soGfgfO8PjbU5svzAOzl92VUnhTuBL7H+XUdCbwIvO03/XqgsTvtSWC537TJOAfzQTjJJcrdziKgFZDgHnRudecfxq+TQmXznuv+o3YHYoA3qDwppLrT2h+h/A9x9IPmVnd7Ye4/dw7QyW+ZxcAV7vsngI/cuBsDHwP/8Jt3HzD4CPFcg5PwQt1l/+M37TJgO9AfJ+F1BNq58/7gbjvW/bwHV7N84cD5QAd3G6cDB/kl+Zzifrdnud9ta/dzjsQ5u+nqt61lwKWVlHOuW5aT3JinlcbprnMPMNLdxlnucFJlMR9pv8Y96JabXun3hLM/+oD/55YrGkgELsXZ5xrj/CiaXq48N5bbhn9SeA0n8TV2v4N1wA1+8RXhJPxQ4DacHzzi9fGh1o5DXgdgL78vo/KksAYY4Tfc0t1xwyqYN979B4hzhycDr1Wwnav9hv8JvOC+H8avk0Jl8/6Pww+yHak8KQxyp0WVn+Y3z0Mc/aD5t3LLvAE86L7vhJMkYnAOonlAB795BwI/H8P3MQt40n0/DueXZbg7PAO4s4JlBrrzVfTdHHP5KljH9NLt4vw4eKKS+Z4HHnPfd8f51RtZybxzgcf9hrvhnBmF4vxCf73c/DOA8ccQ82YqSQpH+57c/bHwKPtNLyC7XHkqTApumQqBbn7TbgHm+sW3wW9ajLvsCVXdb+r7q17VWQaxdsAHIrJPRPbhJIlioIWIhIrI4yKyUUQO4PwDAjTzW35bBevc6ff+INDoCNuvbN5W5dZd0XZK7XH/tjzCPFVRfhtv4RywAa7E+cV4EEjC+Yde4ve5feGOPyoRaQMMB950R32I86v/fHe4DU51TXltgC2q6qtacX7lsPKJyHki8r2I7HXLMJJfvtvKYgB4FbhSRATnjOddVS2o4na34JylNMPZ9y4r/QzdGAZz+Pd4pO/9aKryPWWqan7pgIjEiMiLIrLF3ee/BuKr2F7WzC3bFr9xW3DOiEqV7e/uvgRH/v9oUCwp1A/bcOo14/1eUaq6HedAOBqnzjYO59cnOL/ASmmA4srAqdIq1eYI8/6EU45LjzBPHs4BotQJFcxTviwzgSQR6YWTHN5yx2fh1HF39/vM4lS1qv/c1+D8f3wsIjtx6vOjcBqeccvSoYLltgFtK2kQPabyiUgkTlXORKCFqsbjtA2VfreVxYCqfo/zi3gIzj7yekXz+fH/7trinIlmudt4vdy+F6uqj1cUcxWUn7cq31P5ZX4PdAEGqGoTYKg7XiqZv/z2inCSXam2ONVnBksKdVG4iET5vcJwGt4eE5F2ACKSJCKj3fkbAwU4v8RjgL/XYqzvAteJSFcRiQH+UtmM6pyL3w38RUSuE5EmIhIiIoNFZJI723JgqIi0FZE44P6jBaCqRTh1yv/CqZOe6Y4vAf4LPCEizQFEpLWInFPFso0HHsapmih9XQqMFJFE4CXgHhHp615109H9fhbhJMvHRSTW/Q4HVbN8ETj16JmAT0TOA872m/4yzuc/wv0sW4tIqt/014BngCJVPdploFeLSDf3e/wbMFVVi3Gq5y5wLyUOdcszTESSj7y6Su0CkkUkAqr9PTXGSST7RCQB+GsF26jwngS3TO/i/D81dr+zu91yGiwp1EWf4ezwpa+HgKdwGuK+FJEcnEbnAe78r+Gc/m7HuQLm+9oKVFU/B54GvgI2+G27wmoKVZ0KjMVpGN+B88/7KE7VDKo6E+fqphXAEpyrSqriLZwzpffKVdvcWxqXW80wC+cXJlB2Q9OQ8isTkVNxfkk+q6o7/V4fuesbp6rv4Vzp8hZOO8Z0nCt2inEuse2I0wCb7pb5mMunqjnAHTgHsWycX/wf+U1fhHN10hM4Dc7zOPwX8Os4jcdVOeC9jtP+tBPnjOgOdxvbcM5E/4STnLYBf6D6x445wCpgp4hkueOO+D1V4EmcBucsnH3ui3LTnwLGiEi2iDxdwfK/xTlr24RzpdFbOO1jBrdF3ZiaICJdgZU4DZrVrVM3NUREooHdOFcrrT/CfHNxGsBfqq3YTN1lZwrmuIjIxSISKSJNcS4b/NgSQp1xG7D4SAnBmPLs7kBzvG7BqXYoxqm++I2n0RjA6VoCp+H1Io9DMfWMVR8ZY4wpY9VHxhhjytTr6qNmzZppSkqK12EYY0y9smTJkixVrfBGzoAlBRH5HzAK2K2qJ7njEnAuyUvBufP2clXNdu+6fArnbs2DwARVXXq0baSkpJCWlhaYAhhjTAMlIlsqmxbI6qPJOB2m+bsPmK2qnYDZ7jDAeTj91nQCbsbpt8UYY0wtC1hSUNWvcXpq9Dcap08W3L8X+Y1/TR3f4/Rjcrx95BhjjDlGtd3Q3EJVM9z3O3EesgJOZ1T+nWqlc3gHVWVE5GYRSRORtMzMzMBFaowxQcizhmZVVRE55uthVXUSMAmgX79+v1q+qKiI9PR08vPzf7WsqZ6oqCiSk5MJDw/3OhRjTIDVdlLYJSItVTXDrR7a7Y7fzuG9NCZTzV4L09PTady4MSkpKTjt1+Z4qCp79uwhPT2d9u3bex2OMSbAarv66CN+6Xp4PG5HaO74a93eJk8F9vtVMx2T/Px8EhMTLSHUEBEhMTHRzryMCRKBvCT1bZynJjUTkXSc7m0fB94VkRtweva83J39M5zLUTfgXJJ63XFu+3gWN+XY52lM8AhYUlDVcZVMGlHBvArcHqhYjDGmvij0lZBb4COvwEdOvu+X9wU+cvN/eT8itTk928TX+Pbr9R3NddGePXsYMcLJezt37iQ0NJSkJOfGwUWLFhEREVHpsmlpabz22ms8/XRFXcAbY+oqX3EJeQXF5BY6B+7cgiJyC4oPO4jn5vvIKzz8QJ+b70zLK3DG5RYUEeY7RDy5xEsucZJHU3KIl7yycfHk0k5yycq/EdpcWeNlsaRQwxITE1m+fDkADz30EI0aNeKee+4pm+7z+QgLq/hj79evH/369auVOI0xVecrLmHtzhyWbs1m6ZZsNmbmkev+ks8r8HGoqLjcEkoMBb8cyN2DeVLYQVqHHSIpJJeE0DziJY84zaGx5tJIcogOP0BYWFGlcWhYNBrdFIlpipwYHZCyWlKoBRMmTCAqKoply5YxaNAgrrjiCu68807y8/OJjo7mlVdeoUuXLsydO5eJEyfyySef8NBDD7F161Y2bdrE1q1bueuuu7jjjju8LooxQSE7r9BJAFuzWbIlmxXp+zlYWEw4Pk6P3cYlTXbTLCqPuKhc4sihUUkuscUHiC4+QGTRASKK9hFSUsnBvQQIiYbIBIhu6r7aQ7TfcIz/tKbutHgkPJpAt/A16KTw8MerWL3jQI2us1urJvz1gu7HvFx6ejrffvstoaGhHDhwgPnz5xMWFsasWbP405/+xLRp0361zNq1a/nqq6/IycmhS5cu3HbbbXavgDE1rKREWb87lyVbssvOBDZl5QEQGVLMhUm7uDF5Az18K2i2dxkhvkPOw1EBwqJ/OYA3aQrRyVU6uBMemF/5NaFBJ4W65LLLLiM0NBSA/fv3M378eNavX4+IUFRU8S+K888/n8jISCIjI2nevDm7du0iObm6z0s3xgAcyC9i+dZ9ZUlg+dZ95BQ4DwtMignlohaZPNb8J7rm/0Bc5hJkf57zBOzm3aDPNZAyBFr3gZjEOn1wr64GnRSq84s+UGJjY8ve/+Uvf2H48OF88MEHbN68mWHDhlW4TGRkZNn70NBQfD57yqUxx0JV2ZSVx9Kys4B9rNudgyqECKQ2j+G2zgcYEraGDgeXE52xCMnIcRZOSoVe45wk0G4QNKqwp+kGp0Enhbpq//79tG7tdO00efJkb4MxpgHJK/DxQ/o+lrlnAsu2ZpN90DkTbxIVRp82TZhwYgkDZDVt96cRlv49rHermBM7QY/LIGWwkwgaNfewJN6xpOCBP/7xj4wfP55HH32U888/3+twjKmS7fsO8cHSdJZtySYyIpSocOcV7b6iwkOc4YhQosKcv9HhoUSGhzjz+I2PcuePCA2p9s2Rqkp69qGyaqAlW7JZuzOH4hKnS7SOzRtxdtckzkjIok/xSpplLUS2fgvb9jsrSOgAJ13iJICUwdD4hJr6qOq1ev2M5n79+mn5h+ysWbOGrl27ehRRw2Wfa3A6WOjji5U7mbF4Nc23fsbFofPpEfIz+6UJ2cSxhyZkljRhd3FjMjWOLJqwR51XlsaRRRwFVH5vTojgJpTQXxKKm0QqTDoRoUSEhrBuVw5LtuwjK7cAgNiIUHq1jadPmziGxGdxUuEPxGz/DrYsgENuq3DT9s7Bv/1Q52+TVrXxEdZJIrJEVSu8/t3OFIwxh1FVFv28l+lpP5O78nPO13k8E7qM8HAfhYldCet8G4kFOSTmZdExLxPy0tG8LKQwt8L1FYfFUhiVQH5EIociEjgY3pTc0KYcCGvKgZB4soljrzRhj8aztySWgz4lv6iY3AIfWbmF5BcVc6iwmHyf87fAV0K7xBiGdmpG77bxnNY4k/Z5ywjZ/Cb8sAAO7nE2HN8OupwP7d0zgTi7SKMqLCkYYwDYtvcg7y9JZ3XaVwzKm8m9od8RH5JLYVQzwnrdAr3GEXHCyRUuKwCFB+FgFuRmQt4vr9C8LKLzdhOdl0nTvN2QvQryskDL3/AFSAjENIPYJIht5tTrl76PTYLY5mhUArJ7FWz+Br75xtkOQFwb6HSO2yYwGJq2C9hn1ZBZUjAmiOUV+Ph85U7mLkyj3fZPuTR0PneGZFAcEYmmjoLe44g4cTiEVuFQEREDEW0hvu3R5y0pcap1ypLHbidRlA1nQe5uSE9z3hfmlC1a1gLRpDV0GOFWCQ1xzgys88bjZknBmCBTUqIs/HkvHy/6iZA1HzKKeTwTsgbCoaD1QOj7Z0K7XQhRcYELIiQEYhOdF6lHn7/o0C8J4+BeSDjReVkSqHGWFIwJElv25PH+ki1sT/uUoYdm82BIGlEhReQ3SUH7/hnpMZbIulrlEh7tnIFU5SzEHBdLCsY0YLkFPj5bkcHi77+m865PuDp0AUmyn8KoOEJOvhb6XElU6772i9uUqe0nrzV4w4cPZ8aMGYeNe/LJJ7ntttsqnH/YsGGUXlY7cuRI9u3b96t5HnroISZOnHjE7U6fPp3Vq1eXDT/44IPMmjXrWMM3DUBJibJgQxZ/fWMWzz12Byd/PJJ/7fkN14d/SaOOp8HYN4i4dz1hF/4bkvtZQjCHsTOFGjZu3DimTJnCOeecUzZuypQp/POf/zzqsp999lm1tzt9+nRGjRpFt27dAPjb3/5W7XWZ2uErLmHhz3tp0SSKE5vFEhJyfAfnn7Py+HDRBrKXvs8ZBXN4MPRHQkOUvKReaP87CD3pUqJjEmooetNQWVKoYWPGjOGBBx6gsLCQiIgINm/ezI4dO3j77be5++67OXToEGPGjOHhhx/+1bIpKSmkpaXRrFkzHnvsMV599VWaN29OmzZt6Nu3LwD//e9/mTRpEoWFhXTs2JHXX3+d5cuX89FHHzFv3jweffRRpk2bxiOPPMKoUaMYM2YMs2fP5p577sHn89G/f3+ef/55IiMjSUlJYfz48Xz88ccUFRXx3nvvkZpahUY/c1yKS5RPVuzghZkr6ZQ9j300YltkJ9q3S6Fvu6b0bhtPrzbxxEQc/d/zQH4Rn/6wnbXff85JmZ9xY+giGkk+Bxu3QnvfDb3HEdusUy2UyjQUDTspfH4f7PyxZtd5wslw3uOVTk5ISOCUU07h888/Z/To0UyZMoXLL7+cP/3pTyQkJFBcXMyIESNYsWIFPXr0qHAdS5YsYcqUKSxfvhyfz0efPn3KksIll1zCTTfdBMADDzzAyy+/zG9/+1suvPDCsiTgLz8/nwkTJjB79mw6d+7Mtddey/PPP89dd90FQLNmzVi6dCnPPfccEydO5KWXXqqJT8lUoKRE+fTHDJ6dtZp+ez/hzYjpJES4d9sqZG1JYMXGtizRFN7QFAqTutM6pSt9UhLo264preOjERGK3eqhr79dQOKmD7hQ5jNO9lAYGUtx6sXQ/2pi2p7mXOFjzDFq2EnBI6VVSKVJ4eWXX+bdd99l0qRJ+Hw+MjIyWL16daVJYf78+Vx88cXExMQAcOGFF5ZNW7lyJQ888AD79u0jNzf3sGqqivz000+0b9+ezp07AzB+/HieffbZsqRwySWXANC3b1/ef//94y67+bWSEmXGqp08PXMtqVkzeCXyfVqG70KTB8Lw+5wbtjJW0GznCk7fsYJhez4mRIthH+Qsi2b10nZ8WZJCemQHpEV3onct5cyiOTwQsomSkBByk4eip1xNROr5zr0CxhyHhp0UjvCLPpBGjx7N7373O5YuXcrBgwdJSEhg4sSJLF68mKZNmzJhwgTy8/Orte4JEyYwffp0evbsyeTJk5k7d+5xxVraPbd1zV3zVJUvV+/iyZnraLN7Ds9FTaN9xFa0RQ8Y8RzSccQvjbzthwIQCs41+btXQ8YKYjNWcPK25fTNmktY8Reww5l9f9NUivo/QnjPy2liHbmZGtSwk4JHGjVqxPDhw7n++usZN24cBw4cIDY2lri4OHbt2sXnn39e6TMUAIYOHcqECRO4//778fl8fPzxx9xyyy0A5OTk0LJlS4qKinjzzTfLuuBu3LgxOTk5v1pXly5d2Lx5Mxs2bChrgzj99NMDUm7jUFXmrN3NE7PWEZexgH9HTaVrxHq0aSc4YzLSdfSRq3bCo6F1X2jdlxAgBqCkGPZsgF2roFkn4irpbsKY42VJIUDGjRvHxRdfzJQpU0hNTaV3796kpqbSpk0bBg0adMRl+/Tpw9ixY+nZsyfNmzenf//+ZdMeeeQRBgwYQFJSEgMGDChLBFdccQU33XQTTz/9NFOnTi2bPyoqildeeYXLLrusrKH51ltvDUyhg5yqMm9dJk/MXEfI9jQejp5K34gf0cbJMOxZpMcVVesuoiIhoZDUxXkZE0DWdbapEvtcK6eqfLMhiydmriNv2woeiJ7GkJLFaGwSMuQe6HcdhEUefUXG1BLrOtuYAPl2o5MMdm1Zy5+jP+DsyPkQ3hgG/QUZcCtENvI6RGOOiSUFY6ph0c97+ffMn/h50wbujfmIi6LmICHhyGl3wWl3gN0kZuqpBpkUVLXaj/gzv1afqxhr2pIte3li5npWbdjE3TGfMS5mBqGUIP2ug6H32CMdTb3X4JJCVFQUe/bsITEx0RJDDVBV9uzZQ1RUlNeheGr5tn08MXMdaeu2ckfMDP4X+ynhJYecxuNh90LTFK9DNKZGNLikkJycTHp6OpmZmV6H0mBERUWRnBycjzL8MX0/T8xax4K16dwcPYcXGn9EdNE+6HoBDH8Amlu3IKZhaXBJITw8nPbt23sdhqnnVu3Yz5Oz1vPV6u1cE7WAp5t8QKPC3dD2DDjjAec+AmMaoAaXFIw5Hmt3HuCpWev5YuUOLo9aRFr8B8Tnb4Pmp8CI/zmPfTSmAbOkYAywflcOT85ez6crdnB+5AoWJbxP0sH1EHcSXDwROp9jzx0wQcGSgglqGzNzeXr2ej76YQenh6/l26QPaJXzI0S2h/Nehu6XWG+jJqhYUjBBadvegzw5az0fLEunT9hm5jT/kPb7FwKtYNST0PtqCA33Okxjap0nSUFEfgfcCCjwI3Ad0BKYAiQCS4BrVLXQi/hMw7XrQD7PzNnAlMVb6Spb+eyEz0nNnguFCXD2o9D/RqdDOmOCVK0nBRFpDdwBdFPVQyLyLnAFMBJ4QlWniMgLwA3A87Udn2mY9uYV8sK8jbzx7UaG62K+jJ9L+7zlkNcYht0Pp/4Gopp4HaYxnvOq+igMiBaRIpyegTOAM4Ar3emvAg9hScEcp5z8Il6a/zPTvvmBC4tnsSBqDk19uyG8LZz1CPS5BqKbeh2mMXVGrScFVd0uIhOBrcAh4Euc6qJ9qlr6lJd0oHVFy4vIzcDNAG3btg18wKZeOlRYzGvfbWb23NlcUvQpc8K/JUIKoc1QGPAkdD7X6Y7aGHMYL6qPmgKjgfbAPuA94NyqLq+qk4BJ4HSdHYgYTf1V6Cvh3YWb+HHO21xS9Am3hKylJDKKkF5XwSk3Q4tuXodoTJ3mRfXRmcDPqpoJICLvA4OAeBEJc88WkoHtHsRm6ilfcQmfLlxJxpwXuaDoc66WPRQ0SYbTHiWk99VWRWRMFXmRFLYCp4pIDE710QggDfgKGINzBdJ44EMPYjP1TEmJsuCbr8id/yznFM4jSorIPuE0dNjtRHY5z6qIjDlGXrQpLBSRqcBSwAcsw6kO+hSYIiKPuuNeru3YTP2hxUWsmvM2uvBFhvhWkk8EuztcQptz7qRpi+5eh2dMvdXgHsdpGri8PWyd9TzRP0wmqSSTDGlOZtfxdD//dkJjrYrImKqwx3Ga+i9jBXu++g+N10+nrRaySE5mVZ8HOO3cq2gZYXceG1NTLCmYuqvYBz99ysH5zxKTsZBojeTDkGHIgJsZdeYZRIVbe4ExNc2Sgql78vbA0lfxLfwvYbk7yNIk3uEamgy8jquG96RRpO22xgSK/XeZuiNjBSx6EV0xFSnOZ2HJSbyhV5Iy8BJuGdaJ+JgIryM0psGzpGC8VeyDtZ/AokmwZQGFIVFM9Q3m9eKzOeWUQTw8vCPNmwT386GNqU2WFIw3DmVD2iuw+GU4kM6+yFZMKrmatwqGclafVCaN6ESbhBivozQm6FhSMLVr3zb4/nlYMhmK8tgWfwr/4ko+2d+D83q0ZuqZnenYvJHXURoTtCwpmNqxcyV8+zSsnIYCqxPO5JG9Z/L9zlaMSG3Ox2d3pnurOK+jNCboWVIwgaMKP38NC56CjbPxhcXyVePRPLz7dHZsb8YZqS2YNuxE+rZL8DpSY4zLkoKpecU+WPOhkwwyfuBgRCJvRlzDfw4MIUwTGHt6G64a0JbkptZmYExdY0nB1JzCPFj2Jnz3DOzbQmZEG54uuZl3D5xG1zbNeejcdow8uaXddGZMHWZJwRy/vCxYNAldNAk5lM3a8G78u/B3fO3rz4W9kpl6agonJ1t7gTH1gSUFU317NsJ3z6LL3kSK85kn/flPwUgyY3pzzbnt+Ge/ZLvhzJh6xpKCOXbbl6ALnoI1H+PTUN4vHsyk4pG069yb/xvYjtM7JRESIl5HaYypBksKpmpUYf1MfPOfIGzbt+QRy6u+UXwQPooRA3vwyoB2tE20hmNj6jtLCubIfIWwcioF854kMvsnMjWRl3xXsbLFRYw5rSuf9GxlDcfGNCCWFEzF8g9QnPYKhd88S3T+LjaVtOF/+hs4aQxXn9aBv7SJ9zpCY0wAWFIwhzuQQd7XzxC27BUii/NYWtyd96NvptNpF3F//7YkxFrDsTENmSUFA4DuXkvmlxNJ2PABUVrMZyUDSGt9DUNPP4t/dmlOqDUcGxMULCkEM1UObfyGrBn/ok3mPBprBO/JCPb0uIlRp5/GBc1ivY7QGFPLLCkEqeyfl5H73u20ObiKGG3MGzFXEjv4Vi7qfxLREdZwbEywsqQQhLTYR85b1xNTmMXUE+6iwzm3cFX7lohYFZExwc6SQhD66bNnSS3axJwe/2LMpTd7HY4xpg4J8ToAU7sKc7M5YclEfgjtzpDRN3gdjjGmjrGkEGR+evcBmmgOhWc+RniYtR0YYw5nSSGIZG9dTerWt5nf+Fz6DxzudTjGmDrI2hSCyK6pvydMI2g75h9eh2KMqaPsTCFIbF30MakHvuW75Otpn9Le63CMMXWUJYUgoMVFhHz5J7bSglPG3u91OMaYOsySQhBY+8lTJPu2srH3/cQ3aex1OMaYOsySQgNXkJNFq2VPsjS0J0POv9brcIwxdZwlhQZu3ZQ/00hz0XP+TphdgmqMOQpLCg3Y3s0r6Jr+Ll83GUXfUwZ7HY4xph7wJCmISLyITBWRtSKyRkQGikiCiMwUkfXu36ZexNZgqJI59ffkEU37y/7udTTGmHrCqzOFp4AvVDUV6AmsAe4DZqtqJ2C2O2yqafP3H9AldxEL295IStu2XodjjKknaj0piEgcMBR4GUBVC1V1HzAaeNWd7VXgotqOraFQXwERsx7gZ1oxYKzlVmNM1R01KYjIBSJSk8mjPZAJvCIiy0TkJRGJBVqoaoY7z06gRSXx3CwiaSKSlpmZWWI03I4AABZOSURBVINhNRxrPnqCVsXb2dz3z8Q1ivE6HGNMPVKVg/1YYL2I/FNEUmtgm2FAH+B5Ve0N5FGuqkhVFdCKFlbVSaraT1X7JSUl1UA4DUv+/t20WfE0aWF9GDrySq/DMcbUM0dNCqp6NdAb2AhMFpHv3F/r1b0LKh1IV9WF7vBUnCSxS0RaArh/d1dz/UFt/Tv3E62HCD3374SG2sVlxphjU6WjhqoewDl4TwFaAhcDS0Xkt8e6QVXdCWwTkS7uqBHAauAjYLw7bjzw4bGuO9jt2biUbtunMS9uNL37DfQ6HGNMPXTUXlJF5ELgOqAj8BpwiqruFpEYnIP5f6qx3d8Cb4pIBLDJXX8I8K6I3ABsAS6vxnqDlyp73r+HEGLpPPZRr6MxxtRTVek6+1LgCVX92n+kqh50D+DHTFWXA/0qmDSiOuszsPnb9+ict4QvU37P2a2TvQ7HGFNPVSUpPASUXhWEiETjXCm0WVVnByowU3ValE/knAfZSDIDx/7B63CMMfVYVdoU3gNK/IaL3XGmjlgz/V+0LM5gW/+/0Dgm2utwjDH1WFWSQpiqFpYOuO8jAheSORb52Rm0W/UsC8P7M+S8sV6HY4yp56qSFDLdxmYARGQ0kBW4kMyx2PDOfYRrIVHn/4PQEPE6HGNMPVeVNoVbca4UegYQYBtgHfPXAVnrF9Mt40PmNB3Dmb36ex2OMaYBOGpSUNWNwKki0sgdzg14VOboVNn3we8JoRGpYx/xOhpjTANRlTMFROR8oDsQJeJUUajq3wIYlzmKTV+/RceDP/Blh3s5u2VLr8MxxjQQVekQ7wWc/o9+i1N9dBnQLsBxmSPQokPEznuYdbTjtMt+73U4xpgGpCoNzaep6rVAtqo+DAwEOgc2LHMka97/By1KdrHj1L/SKDrS63CMMQ1IVZJCvvv3oIi0Aopw+j8yHji0Zxspa17ku4iBDD37Eq/DMcY0MFVJCh+LSDzwL2ApsBl4K5BBmcpteudeQtVH7AWPE2KXoBpjatgRG5rdh+vMdp+MNk1EPgGiVHV/rURnDrN77bd03/0pMxPHcdbJvbwOxxjTAB3xTEFVS4Bn/YYLLCF4RJXc6X8gU+PofoVdgmqMCYyqVB/NFpFLpfRaVOOJTXNf5cT8lSzt+FtaNbcnzhljAqMqSeEWnA7wCkTkgIjkiMiBAMdl/JQU5NF4/iOslRMZcvmdXodjjGnAqnJHc3Ufu2lqyJppj9G9JIs1g/9NaqT1RWiMCZyqPHltaEXjyz90xwTGwcwtdFj3X76JHMLgMy48+gLGGHMcqtLNhf9TW6KAU4AlwBkBicgcZvM7f6SDKvGj/2GXoBpjAq4q1UcX+A+LSBvgyYBFZMrsWjWfbllf8GWzqzm728leh2OMCQJVaWguLx3oWtOBmHJKSjj00T3s1qb0uOJhr6MxxgSJqrQp/AdQdzAE6IVzZ7MJoI2z/0eHgrXM6PwQ5yQ18zocY0yQqEqbQprfex/wtqouCFA8BijOzyHu28dYJZ0YOub/vA7HGBNEqpIUpgL5qloMICKhIhKjqgcDG1rwWjv1b3TXvawZ+gzdI8O9DscYE0SqdEczEO03HA3MCkw4JnfXJjpsmMzXUcMYPHyk1+EYY4JMVZJClP8jON33MYELKbhtfeceVKHZ6H9gPYsYY2pbVZJCnoj0KR0Qkb7AocCFFLx2rphDt72z+br5VXTr2s3rcIwxQagqbQp3Ae+JyA6cx3GegPN4TlOTSkoo+OSPZGgiva540OtojDFBqio3ry0WkVSgizvqJ1UtCmxYwWfDzBfpWLieL7s9xtmJCV6HY4wJUketPhKR24FYVV2pqiuBRiLym8CHFjyKD+0n4fvHWSGpDL34Vq/DMcYEsaq0KdzkPnkNAFXNBm4KXEjBZ+17D5Gg+zhw+iNERVSlRs8YYwKjKkkh1P8BOyISClj/zTUkZ8c6Om16jblRZzLo9LO8DscYE+SqkhS+AN4RkREiMgJ4G/g8sGEFj+3v3kORhnLCJX+3S1CNMZ6rSl3FvcDNQGll9wqcK5DMccpY/iWp++bxRYubOLdzl6MvYIwxAXbUMwVVLQEWAptxnqVwBrAmsGEFgZJifJ/dS7om0WfcA15HY4wxwBGSgoh0FpG/isha4D/AVgBVHa6qzxzvht0+lJaJyCfucHsRWSgiG0TkHRFp0O0W6794ljaFm1jV/Q80bxrvdTjGGAMc+UxhLc5ZwShVHayq/wGKa3Dbd3L4Gcf/A55Q1Y5ANnBDDW6rTikpOEjS4oksD+nOsIsbbDGNMfXQkZLCJUAG8JWI/NdtZK6RllARSQbOB15yhwUnAU11Z3kVuKgmtlUXrZv9CvG6n5yBfyQy3C5BNcbUHZUmBVWdrqpXAKnAVzjdXTQXkedF5Ozj3O6TwB+BEnc4Edinqj53OB1oXdGCInKziKSJSFpmZuZxhuEBVaKXvcx62jJg2AVHn98YY2pRVRqa81T1LfdZzcnAMpwrkqpFREYBu1V1SXWWV9VJqtpPVfslJSVVNwzPZKycS7uijWzucBUR4aFeh2OMMYc5proL927mSe6rugYBF4rISCAKaAI8BcSLSJh7tpAMbD+ObdRZe+c8Q4zG0mOk3RRujKl7qnLzWo1S1ftVNVlVU4ArgDmqehVOFdUYd7bxwIe1HVugHdqzjc7ZX5GWMJIWiYleh2OMMb9S60nhCO4F7haRDThtDC97HE+N2/D5M4RqCc2G3e51KMYYUyFPL31R1bnAXPf9Jpyb4xok9RXQeuMUFkf045QevbwOxxhjKlSXzhQatE3z3iJB93Go1/XWx5Exps6ypFBLZPF/2UxLBpx5mdehGGNMpSwp1IKsdQs5MX8V69qMJToy3OtwjDGmUnY7bS3YOetpojWS1PPsqWrGmLrNzhQCrPBAJp12z2Bhk7Np26ql1+EYY8wRWVIIsA1fPEskRTQacpvXoRhjzFFZUgikYh9Ja99kScjJ9Ot3mtfRGGPMUVlSCKAt300jqWQ32SddR0iIXYZqjKn7LCkEUOF3L7BDm9H/nCu9DsUYY6rEkkKA7N+ygk55S1nR8lLiYqO9DscYY6rEkkKApM94mgINp8M5v/E6FGOMqTJLCgFQfHAf7Xd8zHcxw+jUPsXrcIwxpsosKQTAhi8nEUM+YQNv8ToUY4w5JpYUalpJCU1WTmaFdGHAoBFeR2OMMcfEkkIN27H0U1r6tpPR+RrCQ+3jNcbUL3bUqmG5Xz9HpsbR57wJXodijDHHzJJCDcrbuZ6O+79jSbOLSIpv7HU4xhhzzCwp1KAtXzxNMSG0PssuQzXG1E+WFGqIFuTSZvM0voscxEldungdjjHGVIslhRqyac4rNCYPX78b7XGbxph6y5JCTVAlctn/WEsKpw073+tojDGm2iwp1IDMVXNILtzEpvZXERVhD7MzxtRfdgSrAXvnPEOYNqLHeTd4HYoxxhwXO1M4Tvl7ttBh71wWxo8kuXmi1+EYY8xxsaRwnDZ/8QwhqiQOu93rUIwx5rhZUjgeRfmcsOEdvgvvT79ePb2OxhhjjpslheOwZf5bxOt+8nreYJehGmMaBEsKx0EWvcgmbcXAMy/xOhRjjKkRlhSqaf/672ibv5bVbcbSODrC63CMMaZG2CWp1ZQx6z+EaDRdz7UH6RhjGg47U6gG34FdnLhrBt82OosOyS29DscYY2qMJYVq2DTjOSLwETv4Vq9DMcaYGmVJ4VgVF5G45g0WhfTk1FMGeh2NMcbUqFpPCiLSRkS+EpHVIrJKRO50xyeIyEwRWe/+bVrbsVVFxsKpJJZkkdltAmH2uE1jTAPjxVHNB/xeVbsBpwK3i0g34D5gtqp2Ama7w3VO/oIX2KZJnHr2FV6HYowxNa7Wk4KqZqjqUvd9DrAGaA2MBl51Z3sVuKi2Yzua3K3LaZ+3nOUtxpDYJMbrcIwxpsZ5Wv8hIilAb2Ah0EJVM9xJO4EWlSxzs4ikiUhaZmZmrcRZavuMp8nXcE482xqYjTENk2dJQUQaAdOAu1T1gP80VVVAK1pOVSepaj9V7ZeUlFQLkTpK8rJpu/0T5kcPp3vHlFrbrjHG1CZPkoKIhOMkhDdV9X139C4RaelObwns9iK2ymye/SLRFBB66s1eh2KMMQHjxdVHArwMrFHVf/tN+ggY774fD3xY27FVqqSYRisms4xUBg0+w+tojDEmYLw4UxgEXAOcISLL3ddI4HHgLBFZD5zpDtcJmcs+pbkvg/RO1xAZFup1OMYYEzC13veRqn4DVNbP9IjajKWqcr5+lhKNp++513odijHGBJTdfXUUBTt/4sT937Mo8SJaJTbxOhxjjAkoSwpHseWLpyjUUFqecZvXoRhjTMBZUjgCzT9A6y0f8E3EYPp27+J1OMYYE3CWFI5g67zJxOpBCvveaI/bNMYEBUsKlVElYsnLrNITGTLsPK+jMcaYWmFJoRLZq2fRsnAz69tfSWxUuNfhGGNMrbDHcVZi75xnUG1Ez3Ou8zoUY4ypNXamUIGiPZtJ2fM1C+JG0b5lM6/DMcaYWmNJoQJbZzwDqjQdar2hGmOCiyWF8ooOkbT+Hb4JO4WBfXp5HY0xxtQqSwrlZCx4gyZ6gAM9ric0xC5DNcYEF0sK/lQpWTiJdZrMkDMv9joaY4ypdZYU/ORu/I7Wh9axsvVY4mMjvQ7HGGNqnV2S6mfXzKco0WhSz77R61CMMcYTdqbgKtmfQbtdM/k69my6pbTyOhxjjPGEJQXXlpnPEUYx0YPsMlRjTPCypADgK6Tpmjf4VnozZMCpXkdjjDGesaQAZC5+j/jivexKHU9EmH0kxpjgZUdAIH/BC2zRFpx27livQzHGGE8FfVLI37qMNrkrSGt+KS3iYrwOxxhjPBX0SWHHl09xUCNpf+YtXodijDGeC+qkoHl7aJ3+KV9FDqd353Zeh2OMMZ4L6qSQPudFIikk5JSb7HGbxhhDMCeFkmJifpjMYroxbOhwr6Mxxpg6IWiTwr7lH5Ho28WWDlcTHRHqdTjGGFMnBG3fR/vnPcdBTaD/uVd7HYoxxtQZQXmmULhzDe32L+K7phfRLinO63CMMabOCMqk8PNXr1KgYZww/GavQzHGmDolKKuP0nveydt5fXjw5FSvQzHGmDolKJPCiG4tGdHtcq/DMMaYOicoq4+MMcZUzJKCMcaYMpYUjDHGlKlTSUFEzhWRn0Rkg4jc53U8xhgTbOpMUhCRUOBZ4DygGzBORLp5G5UxxgSXOpMUgFOADaq6SVULgSnAaI9jMsaYoFKXkkJrYJvfcLo7zhhjTC2pS0mhSkTkZhFJE5G0zMxMr8MxxpgGpS7dvLYdaOM3nOyOO4yqTgImAYhIpohsqeb2mgFZ1Vy2rrGy1D0NpRxgZamrjqcslT5VTFS1muusWSISBqwDRuAkg8XAlaq6KkDbS1PVfoFYd22zstQ9DaUcYGWpqwJVljpzpqCqPhH5P2AGEAr8L1AJwRhjTMXqTFIAUNXPgM+8jsMYY4JVvWtorkGTvA6gBllZ6p6GUg6wstRVASlLnWlTMMYY471gPlMwxhhTjiUFY4wxZYIyKdS3jvdE5H8isltEVvqNSxCRmSKy3v3b1B0vIvK0W7YVItLHu8gPJyJtROQrEVktIqtE5E53fH0sS5SILBKRH9yyPOyOby8iC92Y3xGRCHd8pDu8wZ2e4mX85YlIqIgsE5FP3OH6Wo7NIvKjiCwXkTR3XL3bvwBEJF5EporIWhFZIyIDa6MsQZcU6mnHe5OBc8uNuw+YraqdgNnuMDjl6uS+bgaer6UYq8IH/F5VuwGnAre7n319LEsBcIaq9gR6AeeKyKnA/wOeUNWOQDZwgzv/DUC2O/4Jd7665E5gjd9wfS0HwHBV7eV3DX993L8AngK+UNVUoCfO9xP4sqhqUL2AgcAMv+H7gfu9jqsKcacAK/2GfwJauu9bAj+5718ExlU0X117AR8CZ9X3sgAxwFJgAM4dpmHl9zWc+28Guu/D3PnE69jdeJLdA8wZwCeA1MdyuDFtBpqVG1fv9i8gDvi5/GdbG2UJujMFGk7Hey1UNcN9vxNo4b6vF+Vzqx16Awupp2Vxq1yWA7uBmcBGYJ+q+txZ/OMtK4s7fT+QWLsRV+pJ4I9AiTucSP0sB4ACX4rIEhG52R1XH/ev9kAm8IpbrfeSiMRSC2UJxqTQ4Kjz06DeXFssIo2AacBdqnrAf1p9KouqFqtqL5xf2qcAqR6HdMxEZBSwW1WXeB1LDRmsqn1wqlNuF5Gh/hPr0f4VBvQBnlfV3kAev1QVAYErSzAmhSp1vFcP7BKRlgDu393u+DpdPhEJx0kIb6rq++7oelmWUqq6D/gKp5olXpx+vODweMvK4k6PA/bUcqgVGQRcKCKbcZ5hcgZOXXZ9KwcAqrrd/bsb+AAnWdfH/SsdSFfVhe7wVJwkEfCyBGNSWAx0cq+uiACuAD7yOKbq+AgY774fj1M/Xzr+WvdqhFOB/X6nm54SEQFeBtao6r/9JtXHsiSJSLz7PhqnbWQNTnIY485WviylZRwDzHF/6XlKVe9X1WRVTcH5X5ijqldRz8oBICKxItK49D1wNrCSerh/qepOYJuIdHFHjQBWUxtl8bpBxaNGnJE4PbJuBP7sdTxViPdtIAMowvkFcQNOPe5sYD0wC0hw5xWcq6s2Aj8C/byO368cg3FOd1cAy93XyHpalh7AMrcsK4EH3fEnAouADcB7QKQ7Psod3uBOP9HrMlRQpmHAJ/W1HG7MP7ivVaX/2/Vx/3Lj6wWkufvYdKBpbZTFurkwxhhTJhirj4wxxlTCkoIxxpgylhSMMcaUsaRgjDGmjCUFY4wxZSwpmKAmIrnu3xQRubKG1/2ncsPf1uT6jQkESwrGOFKAY0oKfnf8VuawpKCqpx1jTMbUOksKxjgeB4a4/fD/zu3s7l8istjtn/4WABEZJiLzReQjnDtMEZHpbgdsq0o7YRORx4Fod31vuuNKz0rEXfdKt+//sX7rnuvXh/6b7l3giMjj4jyHYoWITKz1T8cEjaP90jEmWNwH3KOqowDcg/t+Ve0vIpHAAhH50p23D3CSqv7sDl+vqnvd7i4Wi8g0Vb1PRP5PnQ7zyrsE527VnkAzd5mv3Wm9ge7ADmABMEhE1gAXA6mqqqXdaxgTCHamYEzFzsbpS2Y5TvfeiTgPMAFY5JcQAO4QkR+A73E6JevEkQ0G3lanl9VdwDygv9+601W1BKcbkBSc7qnzgZdF5BLg4HGXzphKWFIwpmIC/FadJ3j1UtX2qlp6ppBXNpPIMOBMnAfP9MTpDynqOLZb4Pe+GOdBNz6c3j6nAqOAL45j/cYckSUFYxw5QGO/4RnAbW5X34hIZ7fnzfLicB5PeVBEUnEeM1qqqHT5cuYDY912iyRgKE7nchVynz8Rp6qfAb/DqXYyJiCsTcEYxwqg2K0GmozzTIEUYKnb2JsJXFTBcl8At7r1/j/hVCGVmgSsEJGl6nRHXeoDnGcv/IDTa+wfVXWnm1Qq0hj4UESicM5g7q5eEY05Ousl1RhjTBmrPjLGGFPGkoIxxpgylhSMMcaUsaRgjDGmjCUFY4wxZSwpGGOMKWNJwRhjTJn/Dy8sFChxLFdyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check our model performance by calculating the loss and the accuracy of the model with the test set."
      ],
      "metadata": {
        "id": "S6xF1pdr5dGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_conf_mat = get_accuracy(model_cnn1,loader=test_loader)\n",
        "print(\"Test set: Average loss: %f, Accuracy: %.0f%%\" % (test_loss,test_acc)) \n",
        "show_confusion_matrix(test_conf_mat)"
      ],
      "metadata": {
        "id": "gFFOWTSX5cgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying some of our results:"
      ],
      "metadata": {
        "id": "7porwGVmPnUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_samples = 5\n",
        "for i in range(0,num_of_samples):\n",
        "  data = x_test_norm[i]\n",
        "  img = np.reshape(data, (28, 28)) \n",
        "  data = torch.Tensor(data).view(-1, 28*28)\n",
        "  data = data.view(-1, 1, 28, 28)\n",
        "  data = data.to(device) \n",
        "  pred = model_cnn(data.double())\n",
        "  pred = pred.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                  \n",
        "  plt.figure(figsize=(2, 1))\n",
        "  plt.imshow(img, cmap='Greys_r')\n",
        "  plt.title(f\"True label:{alphabet_dict[int(t_test[i])]}, Predicted label: {alphabet_dict[int(pred)]}\")\n",
        "  plt.axis('off');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "EVZ2GdC7Pk7a",
        "outputId": "2714200e-b80d-422f-dfe9-d1d7f3d063f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAABUCAYAAADH/HimAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXAElEQVR4nO2de4xcV33HP7+ZO+/ZmbXXu95de22T9dqOMQlyQ5NUEEUBmqCCIlDVRiBKQlFL2xT4A4r6gKYFKipVpVQUQUtL1NKK8qgCrQoF2oIIEqalSdomTSjBaWLi2F7v7GPer9M/Zn7HZ+7OzN7dBGLgfKXVzsy959wzd37f8zu/17lijMHDw2M4Ys/2ADw8Lmd4gnh4jIEniIfHGHiCeHiMgSeIh8cYeIJ4eIzBZUkQEbldRO6NeO5dIvKxHV5nx20vB4iIEZHD/dcfEpF3fB+uOfK3EZFD/TEFEfq5UUTO7HAMO267XYwliIiUnb+uiNSc96/5fgzw2YSIJEXknSLyiIhUROS7IvI5EfnJiO1v7N+3sohs9Pu543sxVmPMG40x74owpi+LyBu+F2O4XCE93Cki/ykiVRF5qn8fbtuq7VimG2PyzkUeA95gjPnSkAEExpj2TgZ/meNTwD7g54D7+p/dBPwU8IWIfTxpjNkvIgLcCnxKRE4ZYx5yT/ohvoeXA/4YeBnwS8C9QBO4HngD8PFxDXe0xFIVJyJvF5GngI8OU72hJUBKRP5ARB4XkXP9JUEm4vXeLyJPiMi6iHxTRF4UOiUtIn/bn6X/Q0SudtrOi8inReSCiJwWkTdFvOZLgJcCtxpjThljmv2/zxtj3hylDxemh3uAEnC8f7++JiLvE5GLwF1b3SMReZuInBWRJ0Xk9aHx3i0i73be3yoi9/fv2aMicouIvAd4EfCBvlb7QP/cYyLyRRFZ6Wu5n3H6mRKRz/b7+QawGPU7i8gdIvI//d/lOyLyi0PO+Q0RWRaRx9xVydORl1D/R4BfBm4zxnzRGFMzxnSMMfcaY27fqv3TsUFmgd3AQeAXIpz/XuAI8HzgML2Z+Z0Rr/Vv/Xa7gb8BPikiaef4rcAnneP3iEhCRGLA3wMP9K/3YuAtInLzsIv0VfCr+29fApwyxjwja10RiYnIK4FJ4L/6H18LfAfYC7yHMfdIRG4B3kqPtEv98Y261o8Dfwm8rX+9G4DHjDG/CXwVuNMYkzfG3CkiOeCL9O7bDHAb8EEROd7v7k+AOjAHvL7/FxXngZcDBeAO4H0ictI5Pgvs6X/P1wF/KiJH+8ciy4uIfFBEPjhiDDcBTxhj/n0b474EY0ykP+Ax4CX91zfSU1Np5/jtwL2hNqb/5QSoAIvOseuB0yOutamv0PEScHX/9V3A151jMeAsvZnyWuDxUNtfBz7qtP3YiGt8BPi48343sAqsAfWI9+xGoNtvtwLcT28m0+/4uHPu2HsE/AXwXufYEb2//fd3A+/uv/4w8L4RY/oyvaWyvv9Z4Kuhcz4M/DYQB1rAMefY7436bYBD/TEFI47fA7zZuTdtIOcc/wTwjgj34kbgTMTf4Ldc+eh/dqb/m9SBg+Pab+ltGIMLxph6xHOngSzwzd5SHPo3IR6lsYi8Ffh5YJ7eD1CgN/MontAXxpiu9Dwceu68iKw658bpzaJb4SK9mVr7XQEm+0vG/40y7j6eNMbsH3HsCef1VvdoHvimc/7/jbnmAvCPEcd3ELg2dI8C4K/6YwpC4xx33QGIyMvoEe0IvYkryyXtCVAyxlRCfc/zNOUlhIv0tJ+F6dmEAT3yy9BWfTwdgoTTgCv0vhQAIjLrHFsGasBzjTHf3c5F+vbGr9FbHj3YJ0CJwS+24JwfA/YDT9KboU4bY5bYPv4Z+FUR2W+eoWXWELj3cKt7dBbnewIHxvT7BKNthfDv9gTwFWPMS8Mnikic3j1cAB6OcF23bQr4ND0Hx2eMMS0RuYfB322XiOQckhwA/punIS9D8C/0bK5rzA6WWc9kHOQB4Lki8vy+fXCXHjDGdIE/o7cGnQEQkX2jbIEQJuj9SBeAQETeSU+DuPgxEXlVf1Z4C9AAvg58A9joOxMyIhIXkRMi8oKtLmqM+QLwr/TsmWul5/JNANe55/WN47sjfI+trrfVPfoEcLuIHBeRLL2ZeRT+HLhDRF7ct332icix/rFzwBXOuf8AHBGR1/bttoSIvEBErjTGdIC/o+dAyPbtktdF/EpJIEXvd2v3tckw9/jv9O/ti+jZK598mvIyAGPMI/SWjB8XkZeqHAA/EaX9M0YQY8y3gN8FvkRvCRIOJr0d+DbwdRFZ7593lK3xT8DngW/RU8F1BlU+wGforaVLwGuBVxljWv0f+OX0DL3T9GamjwDFYRcSkQdlML7zSnoC9DF6a9bTwGsA94daAL4W4XtEwch7ZIz5HPBH9GbEb/f/D4Ux5hv0jWJ6NtNX6C2lAN4P/LSIlETkj40xG/QE9zZ6Wvcp4PfpCTfAnUC+//ndwEejfJF+v2+iR+wS8Grgs6HTnuofexL4a+CNxhjVVJHlpe/h+tCY4fwKPVfvH9KzBc8A76InM4+P+x5ifMHUjiEiSXqa8ypjTOvZHo/HMw9PEA+PMbgsc7E8PC4XeIJ4eIyBJ4iHxxg8nTjIjwweffRRo7aaiOAErwbgHnOitvbzUe3CfbjQfsKfu9cZdb47hjD088XFxa0H9SMMT5CI2Eq4o5BmJ9ca50RREoxqP4pEHtHhCRIBowQ8Hh/MfIiiZcL9hskQbheLxTZ97r7X41uNPZSLRCzmV9dR4AmyQ2xXK2ynz61I45437HgUjfG9GP8PIzxBtgFXqIYJ2DABh+0tcYZpH1czbTUOV0u4192JPeThCbJtjFr3h89RjDp3nFYYZ5CPI9C4sWq7YRrHYzQ8QXaAcQI2TLijCqR77jD7ZBwx3WNu206ngzHG2hzeYN8ePEG2ge3MvFuRKOy+HUWIYUsmt50e73a7GGPodDoD14rFYogInU4HEbHvvRaJBk+QCNhq3R7VI6R9qOdp1Gze7XbpdDr2r9vt2rbdbnegr3a7TafTodFo0G63KZfLNBoNoOdlm5qaIpFI2D4KhQLxeNwTJCI8QSIgypJqOwKnQq6z/jBjWgW/2+3S7XYtCVW4h8U6VJO0223a7TaxWIxms0m326VeryMiZLNZ25d39W4NT5AIiOI9cj8Le50UKsAwqCVarZYV8FgsRiwWsxpBCaGfZzIZksmk7bNWqwEQBIElkts+lUoRi8U4c6ZXFDkxMYGIkEgkvBaJAE+Qp4EwYcIECdsHSg7AagYlSiwWIwiCgWWYu6TS9s1m07Y3xlCpVGg0GlQqFer1OqurqzQaDer1Op1Oh0QiYftNJBID7z1BtoYnSASM0gijNEosFhvQEM1mk1arRbPZtMIfRjKZJJMZ3PbJGEOj0aDZbFrNoK+1z1KpRLVa5cKFC1SrVarVKp1OhyAIiMVibGxskEwm2bdvH5OTk+RyOVKp1MD38hgNT5BtYFxU2z3H9SjpEqrdbtNqtWyb8J8a1qpVVCNUKhVqtdqmJZheo1qt0mq1iMVipFIpu/zKZDIkEglyuRzJZJLp6WnS6bRdsnlyRIMnyDYxKtDmumTVuG42m7TbbRqNBq1Wa0DQ4/E4QRAQj8eJx+PU63VKpRL1et2+LpVKlMtl6vU6tVptQANNTEyQSqXIZrOkUin7fteuXaTTaQqFgtVK8Xh8wObw5IgOT5AdQAXNtSlgs82hdoSe22g0aDQaVKvVgX4AGo0GtVrNLsUqlQrVatWSLJlMksvlmJycJJPJ2P/ZbNYSIQgCSwiXGG7sY6uAo8cgPEEiYJQx6xrQwwJ6sVjMZvy2223W1tYolUqcO3eOVqtFvV6n1WpZ0lSr1U2uXzWqFxcXmZub48SJE0xPT5PP50kkEsTjcbvscjWEjk0Dh54YO4MnyA4QFr6wJlGoQAZBQCKRIJPJsL6+TqPRoFwuW49TrVaz2iWbzZLL5cjlcmSzWYrFIhMTE1xxxRXMzs4yNTVFNpsdIMewMQwjgyfI9uEJEgHhQJ7+qdHtJhEOc/cmk0m63S7FYpGLFy9Sq9VYXl7mkUceoVwuUy6XraY4ePAgU1NTLCwssH//fo4ePcrMzAzFYpFsNrtJWw1zIXsX7jMHT5CIUON7WCr5qAChiAykdajLViPdrVZrpB2ze/durrzySqampsjn88Tj8U15VsOWTVGI4TVJdHiCRIQxhna7bWdsGJ1bpRFttT+UJOVy2S6nlChunpVr0B86dIjjx4/bZZTGPdTWGEXUqJ4qT5Jo8ASJAE0FCS9jFOEEQhVqEaHValGpVFheXub06dNcuHDBxjbcvmKxGIlEgmq1yvLyMg888ADpdJoDBw4wNTVlj4e1xk5qPLy7Nzo8QSKgXu895WFYVq8uvTRVRAVZ0Ww2OXfuHI8++igPPfQQ1WqV1dVVNjY2bJ9KqCAI2NjYoFQq0Ww2eeihh3jFK17BddddZ+MaGnQMF1GNwigyeBslGjxBImCU8e3aGq6r1dU0sViMbDbL1NQU+/bts0Z6LBajXq/blJRUKkUqlbIJipVKhTNnznDq1CmWl5e57rrrWFhYsPlUrj00asyj3o9KnfHYDE+QCAgH2tRYVhtDj+v7YQSZmZmhWq0SBAEXL14cSC/RvlKpFEEQ0Ol0WFtbo1wuc/bsWVKpFN1ul5tuuom9e/eSyWRsSspWQj5sOeYRHZ4gERAEvdsUnnk1BuEWM7laRV23uoSanp5mfX2dTCZDJpOxlX5a8NRoNAbSRHK5nE1bf/DBB2k0Gtxyyy0cOnRo4PrumNxxhsngjt/XpkeDJ0gEKEHa7fbQmIdb763HgyCwiYOaJNhoNCiVSjZ/SgW13W7TbDapVqsUCgUmJyeZmJig3W5z7tw5VlZWOHXqFPfddx+HDx9mfn7e2jth0ur1R5FjWHGWx2h4gkSALqnCqerhGnF3Izk9V20MJcfq6iq1Wo12u00QBAMzuSYpulm7QRBQLBZZW1ujUqlw9uxZlpeXbURdSRsW/LBG2Unlo4cnSCSMinuE3b5KEFfLQI9g9Xqd5eVl1tbWbA6Wxkc0ttJsNm0qSjabJZ1Ok0gkSKVSXLx4kbW1Nc6dO8f58+cpFosDToFh3qphyy6P7cETJAKG1XyEZ2zVFIBNd4/FYlZ71Go1yuWyjYHU6/WBpEbVGm7yomu4ZzIZFhYWmJ+ftxsxaFt3nGGCuAmVwECg05Nma3iCREA4Uj4sNwsuCZ8Spdls2opCNymxUqnQbDY3aSb1bOkGCyJCMpkkmUwyMzPDnj17mJmZoVAoWIKEl31hMg+rXlQPmMfW8ASJABVWTQ1x/+ASYVwbxCWNHisUCjZLV4uhNNNXjXoRIZ1OW+Kp8X7w4EEWFxcpFou0Wi02Njas88Ado+uOBjbFS7Qe3U2P9xgNT5AIcAuN3KRFJYlGtt1gYdibFAQBuVyOdDptvVu1Ws2+DoKAIAisd0tztVT77Nq1i6WlJbLZLK1Wy2YShwU+bNeoEa/fQwup1AvmMR6eIBEQJoQLlxQqnBr7cHcPabVaFAoF0um0PTcIgoHCqU6nw9TUFDMzM6yurrK+vk4ymcQYw5kzZxARHn74YSvkmhDpCrqOL5lMEgQBc3Nz5PN55ubmbJ26W2XoMR6eIBHgEmRYZNoVNhVa/VMCpdNpWx6rM348Hre16gq1MWq1miUbwFNPPUWlUrEESKVSA5pAA46qMQqFAplMhuPHjzM9Pc2uXbuswe/minmMhydIBLh2hMIljBscdIVfhVt3NlxZWWF1dZVSqUStVrPeKdUSjUbDluMCtmrQGGMJod4yNeSVEEqs6elpstks+/fvp1gscuzYMfL5vC3RTSaTmx784zEaniARoHEGd8scdeMOqz93NYcuyzTtvVqtsrGxYeMgSirdtaRcLtNut8nn8xQKBUs41yCHS1pNd0rR1JS5uTlbbFUoFJibmyOdTgObC7g8toYnSAS4hrfO4OP21e10OsTjcdLpNI1Gg7W1Nc6ePcvp06dZWVmxKfGpVMr2oVuEKskSiQTZbNYGDKvVqg0gKhmSySSzs7MUi0Wuvvpq9uzZw+7du22JL2BjLq59pHtoeaJsDU+QCHCj1Oq1CpNDP1dtoTN+pVLh/PnznD9/npWVFarV6kCBlJItvG+Vbtmjni+1MfS9bvtz7Ngx5ufnufLKK5mcnCSZTNodFXVziE6nY20f1VwuGT1GwxMkArSiUGvI9b0uodQlq9t+agFVIpFgY2ODs2fP2iKpZrNpI+Tqhm232zayruRpt9tUKhW7EdyRI0eYmZlhbm6OYrFo98EqFouk02mCILBBRh2zu6FDuVwGsB4w6BF/9+7dz9p9/UGAJ0gE6HpfXbFqRKv3SCPjGxsbA4E5EaFSqVhy6A6LOnvrrK5xD23j2glBEJDNZjl06BBLS0tMT0+Ty+UGXMlafKWbzunDcmBw02vVTGF7xmM0/J2KgPX1dftaPVL6X43vTqdDrVYbmLWVPBo1132wlAyxWMx6lVSTpFIp0uk0J06cYGFhgeuvv56lpSV2795NLpcbSIDUMXQ6HbtHb71et1WJcMkV7T5oBy4FGJeWlr7Pd/MHC54gEaAlsuq10kh2uVy2cQx3Gx8lR6vVolqtUq/X7fJH7RTtD7A5V81mk3w+T7FYZO/evSwuLrK0tMTBgwdtOoqb7qJj0SVas9mkVqtZJ4EWbWlkvdvt2t0bNVjoMR6eIBGgUWwNsKnwr6+v0263rVAqUVQIVZjdnd01gKh96HLr8OHD1j37vOc9j/379zMzM2MF2RV+tYNUc6gxrmkp7lZCmUzG2jQaP1ECey/W1vAEiYC1tbUBgujMrTEL1Qw6i2vE290OqN1u29euYOqWpFNTUxw6dIirrrqKI0eOsGvXLnK5nCWC7hLvaii1LZQYuuRzbSC1VbQPdSKEx+ExHJ4gEXD//fdbe8GNh+jyplqt2v/uNkDhTaXV01StVpmfn2ffvn0cPnyYkydPsnfvXvbs2WOLpNyERfcRCuHN5nSJt7y8TKVSsW5euFQPEo7jAJawHuPhCRIBFy5cQKT3AEw3s1drPSqVihViN6tXhdWtRNSoeD6fZ3Z2lqWlJa644gomJyfJ5/PA4C6OOvOHNYe7a7wu8yqVCnApkq9w9+pys5J9wdTW8ASJgIcfftgKeTwet0TR3Cg3sOc+rMYNCNZqNS5evMji4iLHjx/nqquu4pprriGfz1vvlD6R1k081C1H3ei9Wymo9seFCxdYW1uzSYmq7bR4K5/PDzz1Vm0ij/HwBIkADb7BpQo9N54Q1hBhD5UKdSKRoFgs8pznPMduKar9uM9FV1tBjXt1Cw+D2kP6FColrxJY2+omEa5m8hpka3iCRMDExIR9rdFr9UapgAKbEgFFxD559ujRo9x8882cPHmSkydP2uxdrUNXV7D2qySp1WrUarVNj2xT4rnu5PX1dZtnVSgU7K4pgM3+VSNeNYzHeHiCRIA+FRawpbHhzN4wXA+WPjJtaWmJ2dlZcrmczdxVF6x6o9y4hfuEXIW7B5fCjc00Gg2b/KhQYmhqjEd0eIJEQDabBS4tpcJlty5UWLWW/NixY7zwhS/kxIkTnDx5kk6nw8rKyqalk5tCr7aCPtBTU+FVY7lFWrqUUjKVSiV7TPO1VJNoDpjaO36JtTU8QSJAZ+3wcwDdDeXC0M2o9+zZw9LSEnv37iWVSg08G6TVam2KR7geMvcR0m4mcdhL5Y5J+9SMYs0XU4eCXk+Nfo/x8ASJgPBzAN0nPbmFUa1Wi2QyycTEBAcOHOCGG27g4MGDHDlyBGMM6+vrA4E93bTBrc1QF68eV/et6wQABhIV3f1/NStYC6n0nHANysbGho+FRIBPxomAYTO8YtgsrMVSs7OzTE5O2uCfagU3l2pYTCKsRdy/UbXx4eWf6xZ2MSxo6DEa4tehHh6j4TWIh8cYeIJ4eIyBJ4iHxxh4gnh4jIEniIfHGHiCeHiMwf8D6pg4H5oQ1QcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 144x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we implemented a novel network called CapsNet:"
      ],
      "metadata": {
        "id": "mWnFPOaVIavV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "# from torchvision import datasets, transforms\n",
        "# from capsnet import CapsNet\n",
        "# from data_loader import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10\n",
        "LEARNING_RATE = 0.01\n",
        "MOMENTUM = 0.9\n",
        "n_features = 10\n",
        "'''\n",
        "Config class to determine the parameters for capsule net\n",
        "'''\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # CNN (cnn)\n",
        "        self.cnn_in_channels = 1\n",
        "        self.cnn_out_channels = 256\n",
        "        self.cnn_kernel_size = 9\n",
        "\n",
        "        # Primary Capsule (pc)\n",
        "        self.pc_num_capsules = 8\n",
        "        self.pc_in_channels = 256\n",
        "        self.pc_out_channels = 32\n",
        "        self.pc_kernel_size = 9\n",
        "        self.pc_num_routes = 32 * 6 * 6\n",
        "\n",
        "        # Digit Capsule (dc)\n",
        "        self.dc_num_capsules = 26\n",
        "        self.dc_num_routes = 32 * 6 * 6\n",
        "        self.dc_in_channels = 8\n",
        "        self.dc_out_channels = 16\n",
        "\n",
        "        # Decoder\n",
        "        self.input_width = 28\n",
        "        self.input_height = 28\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=1\n",
        "                              )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "\n",
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9, num_routes=32 * 6 * 6):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "        self.num_routes = num_routes\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
        "            for _ in range(num_capsules)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), self.num_routes, -1)\n",
        "        return self.squash(u)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "\n",
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "        if USE_CUDA:\n",
        "            b_ij = b_ij.cuda()\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij, dim=1)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = self.squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_width=28, input_height=28, input_channel=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_width = input_width\n",
        "        self.input_height = input_height\n",
        "        self.input_channel = input_channel\n",
        "        self.reconstraction_layers = nn.Sequential(\n",
        "            nn.Linear(16 * 26, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, self.input_height * self.input_width * self.input_channel),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        classes = torch.sqrt((x ** 2).sum(2))\n",
        "        classes = F.softmax(classes, dim=0)\n",
        "\n",
        "        _, max_length_indices = classes.max(dim=1)\n",
        "        masked = Variable(torch.sparse.torch.eye(26))\n",
        "        if USE_CUDA:\n",
        "            masked = masked.cuda()\n",
        "        masked = masked.index_select(dim=0, index=Variable(max_length_indices.squeeze(1).data))\n",
        "        t = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
        "        reconstructions = self.reconstraction_layers(t)\n",
        "        reconstructions = reconstructions.view(-1, self.input_channel, self.input_width, self.input_height)\n",
        "        return reconstructions, masked\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, config=None):\n",
        "        super(CapsNet, self).__init__()\n",
        "        if config:\n",
        "            self.conv_layer = ConvLayer(config.cnn_in_channels, config.cnn_out_channels, config.cnn_kernel_size)\n",
        "            self.primary_capsules = PrimaryCaps(config.pc_num_capsules, config.pc_in_channels, config.pc_out_channels,\n",
        "                                                config.pc_kernel_size, config.pc_num_routes)\n",
        "            self.digit_capsules = DigitCaps(config.dc_num_capsules, config.dc_num_routes, config.dc_in_channels,\n",
        "                                            config.dc_out_channels)\n",
        "            self.decoder = Decoder(config.input_width, config.input_height, config.cnn_in_channels)\n",
        "        else:\n",
        "            self.conv_layer = ConvLayer()\n",
        "            self.primary_capsules = PrimaryCaps()\n",
        "            self.digit_capsules = DigitCaps()\n",
        "            self.decoder = Decoder()\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
        "        reconstructions, masked = self.decoder(output, data)\n",
        "        return output, reconstructions, masked\n",
        "\n",
        "    def loss(self, data, x, target, reconstructions):\n",
        "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
        "\n",
        "    def margin_loss(self, x, labels, size_average=True):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
        "\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "\n",
        "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def reconstruction_loss(self, data, reconstructions):\n",
        "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
        "        return loss * 0.0005\n",
        "\n",
        "# def new_margin_loss(x, labels, size_average=True):\n",
        "#         batch_size = x.size(0)\n",
        "\n",
        "#         v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
        "\n",
        "#         left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "#         right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "#         loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "#         loss = loss.sum(dim=1).mean()\n",
        "\n",
        "#         return loss\n",
        "\n",
        "def train_capsnet(model, optimizer, train_loader, epoch):\n",
        "    capsule_net = model\n",
        "    capsule_net.train()\n",
        "    n_batch = len(list(enumerate(train_loader)))\n",
        "    total_loss = 0\n",
        "    for batch_id, ar in enumerate(train_loader):\n",
        "        data = ar[:,1:].type(torch.double)\n",
        "        target = ar[:,0].type(torch.int64)\n",
        "        target = torch.sparse.torch.eye(26).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
        "        train_loss = loss.item()\n",
        "        total_loss += train_loss\n",
        "        if batch_id % 100 == 0:\n",
        "            current_acc, current_loss, _ = get_accuracy_capsnet(capsule_net, train_loader)\n",
        "            # tqdm.write(\n",
        "            #     \"Epoch: [{}/{}], train accuracy: {:.6f}%, loss: {:.6f}\".format(e, N_EPOCHS, valid_acc,\n",
        "            #                                                               valid_loss / len(val_loader)))\n",
        "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}%, loss: {:.6f}\".format(\n",
        "                epoch,\n",
        "                N_EPOCHS,\n",
        "                batch_id + 1,\n",
        "                n_batch,\n",
        "                current_acc,\n",
        "                current_loss\n",
        "                ))\n",
        "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,N_EPOCHS,total_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def get_accuracy_capsnet(capsule_net, loader):\n",
        "    capsule_net.eval()\n",
        "    final_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    for batch_id, ar in enumerate(loader):\n",
        "        data = ar[:,1:].type(torch.double)\n",
        "        target = ar[:,0].type(torch.int64)\n",
        "        target = torch.sparse.torch.eye(26).index_select(dim=0, index=target)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output, reconstructions, masked = capsule_net(data)\n",
        "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
        "\n",
        "        final_loss += loss.item()\n",
        "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
        "                       np.argmax(target.data.cpu().numpy(), 1))\n",
        "        \n",
        "        for y in np.argmax(masked.data.cpu().numpy(), 1):\n",
        "          pred_list.append(y)\n",
        "\n",
        "        for y in np.argmax(target.data.cpu().numpy(), 1):  \n",
        "          true_list.append(y)\n",
        "\n",
        "    conf_mat = confusion_matrix(true_list, pred_list, labels=list(range(0,9))+list(range(10,25)))  \n",
        "    acc = correct * 100 / len(loader.dataset)\n",
        "    \n",
        "    return acc, final_loss, conf_mat"
      ],
      "metadata": {
        "id": "SL73PRG8IZlv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "config = Config()\n",
        "\n",
        "capsule_net = CapsNet(config)\n",
        "capsule_net = torch.nn.DataParallel(capsule_net)\n",
        "if USE_CUDA:\n",
        "    capsule_net = capsule_net.cuda()\n",
        "capsule_net = capsule_net.module.double()\n",
        "\n",
        "optimizer = torch.optim.Adam(capsule_net.parameters())\n",
        "# capsule_net.margin_loss = new_margin_loss\n",
        "for e in range(1, N_EPOCHS + 1):\n",
        "    train_capsnet(capsule_net, optimizer, train_loader, e)\n",
        "    valid_acc, valid_loss, _ = get_accuracy_capsnet(capsule_net, val_loader)\n",
        "    tqdm.write(\n",
        "        \"Epoch: [{}/{}], validation accuracy: {:.6f}%, loss: {:.6f}\".format(e, N_EPOCHS, valid_acc,\n",
        "                                                                  valid_loss / len(val_loader)))\n",
        "\n",
        "torch.save(capsule_net.state_dict(),  \"/content/gdrive/My Drive/Intro_to_Deep_Learning/Project/capsnet.pt\")"
      ],
      "metadata": {
        "id": "qkQTNKZgy373",
        "outputId": "1cbe7bbc-4dfa-43ec-de82-07003feac0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b907c61e48e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# capsule_net.margin_loss = new_margin_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     tqdm.write(\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mtrain_capsnet\u001b[0;34m(model, optimizer, train_loader, epoch)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mcurrent_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# tqdm.write(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m#     \"Epoch: [{}/{}], train accuracy: {:.6f}%, loss: {:.6f}\".format(e, N_EPOCHS, valid_acc,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mget_accuracy_capsnet\u001b[0;34m(capsule_net, loader)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigit_capsules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_capsules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0ms_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_ij\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mv_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36msquash\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msquash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0msquared_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquared_norm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now() \n",
        "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "\n",
        "# torch.save(capsule_net.state_dict(),  \"/content/gdrive/My Drive/Intro_to_Deep_Learning/Project/capsnet_\" + dt_string + \".pt\")\n",
        "capsule_net.load_state_dict(torch.load('/content/gdrive/My Drive/Intro_to_Deep_Learning/Project/capsnet_07_01_2022_13_50_36.pt'))"
      ],
      "metadata": {
        "id": "jykfmImpvLDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bd334c-3b4a-420c-9262-49c9129bbb3a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, test_loss, test_conf_mat = get_accuracy_capsnet(capsule_net, test_loader)\n",
        "tqdm.write(\n",
        "    \"test accuracy: {:.6f}%, loss: {:.6f}\".format(test_acc, test_loss / len(test_loader)))\n",
        "show_confusion_matrix(test_conf_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "jntWwfcqvMCi",
        "outputId": "d80d918b-ded0-4091-cb71-c1c71773c82c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1a34e564f06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m tqdm.write(\n\u001b[1;32m      3\u001b[0m     \"test accuracy: {:.6f}%, loss: {:.6f}\".format(test_acc, test_loss / len(test_loader)))\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_conf_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mget_accuracy_capsnet\u001b[0;34m(capsule_net, loader)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigit_capsules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_capsules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d050ddedeb1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_capsules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mu_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.83 GiB (GPU 0; 11.17 GiB total capacity; 8.92 GiB already allocated; 1.63 GiB free; 9.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}